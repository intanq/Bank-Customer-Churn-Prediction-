{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a9f26e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree,ensemble\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, roc_auc_score, roc_curve, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c74c97a",
   "metadata": {},
   "source": [
    "# Predicting Bank Customers Churn\n",
    "By: Ni Putu Intan Maharani (23522048)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de3a2bc",
   "metadata": {},
   "source": [
    "## 1. Data Preparation and Feature Engineering\n",
    "In this step:\n",
    "1. Import the dataset\n",
    "2. Identify missing values\n",
    "3. Data type checking - for transformation\n",
    "4. Splitting datasets to X (independent variables) and y (dependent variables)\n",
    "4. Imbalance data analysis - including removing data with missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f63659",
   "metadata": {},
   "source": [
    "### 1.1. Import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecd919e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_folder = \"/Users/intanmaharani/Desktop/Semester I August 2022/IF5171 - Pembelajaran Mesin DSAI/Prac3\"\n",
    "df_train_path = os.path.join(src_folder,\"churn_train.csv\")\n",
    "df_test_path = os.path.join(src_folder,\"churn_test.csv\")\n",
    "\n",
    "df_train = pd.read_csv(df_train_path)\n",
    "df_test = pd.read_csv(df_test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3262f06b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x116</th>\n",
       "      <th>x117</th>\n",
       "      <th>x118</th>\n",
       "      <th>x119</th>\n",
       "      <th>x120</th>\n",
       "      <th>x121</th>\n",
       "      <th>x122</th>\n",
       "      <th>x123</th>\n",
       "      <th>x124</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.067563</td>\n",
       "      <td>-2.172492</td>\n",
       "      <td>-1.713774</td>\n",
       "      <td>-0.146854</td>\n",
       "      <td>-0.685219</td>\n",
       "      <td>-0.933838</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-4.476051</td>\n",
       "      <td>-1.472306</td>\n",
       "      <td>...</td>\n",
       "      <td>4.607926</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.773809</td>\n",
       "      <td>0.766531</td>\n",
       "      <td>6.307142</td>\n",
       "      <td>9.074515</td>\n",
       "      <td>-2.694049</td>\n",
       "      <td>0.330964</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.099622</td>\n",
       "      <td>0.584803</td>\n",
       "      <td>-6.089758</td>\n",
       "      <td>-0.252186</td>\n",
       "      <td>-0.334912</td>\n",
       "      <td>-4.671281</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.387076</td>\n",
       "      <td>-0.664552</td>\n",
       "      <td>...</td>\n",
       "      <td>15.889763</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.065852</td>\n",
       "      <td>0.994304</td>\n",
       "      <td>-0.028411</td>\n",
       "      <td>-21.472850</td>\n",
       "      <td>5.626095</td>\n",
       "      <td>1.293455</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.648421</td>\n",
       "      <td>3.881137</td>\n",
       "      <td>0.961359</td>\n",
       "      <td>0.217361</td>\n",
       "      <td>-1.471850</td>\n",
       "      <td>-0.975352</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.850146</td>\n",
       "      <td>-4.011487</td>\n",
       "      <td>...</td>\n",
       "      <td>13.770410</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-8.598553</td>\n",
       "      <td>-2.958302</td>\n",
       "      <td>-12.784030</td>\n",
       "      <td>-36.855873</td>\n",
       "      <td>0.356093</td>\n",
       "      <td>1.499790</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.005775</td>\n",
       "      <td>-2.726153</td>\n",
       "      <td>2.891378</td>\n",
       "      <td>-0.038325</td>\n",
       "      <td>2.280847</td>\n",
       "      <td>1.761478</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.116188</td>\n",
       "      <td>-4.610151</td>\n",
       "      <td>...</td>\n",
       "      <td>5.904901</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.194975</td>\n",
       "      <td>-7.798308</td>\n",
       "      <td>10.910515</td>\n",
       "      <td>15.226094</td>\n",
       "      <td>-10.440813</td>\n",
       "      <td>-0.735116</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.044396</td>\n",
       "      <td>2.803576</td>\n",
       "      <td>-1.923381</td>\n",
       "      <td>-0.116657</td>\n",
       "      <td>-1.574199</td>\n",
       "      <td>6.098627</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-13.956141</td>\n",
       "      <td>13.785099</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.603703</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.330789</td>\n",
       "      <td>-8.249825</td>\n",
       "      <td>-12.680490</td>\n",
       "      <td>40.192302</td>\n",
       "      <td>-5.037065</td>\n",
       "      <td>1.679262</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 126 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         x0        x1        x2        x3        x4        x5   x6   x7  \\\n",
       "0  0.067563 -2.172492 -1.713774 -0.146854 -0.685219 -0.933838  4.0  2.0   \n",
       "1  0.099622  0.584803 -6.089758 -0.252186 -0.334912 -4.671281  4.0  2.0   \n",
       "2  0.648421  3.881137  0.961359  0.217361 -1.471850 -0.975352  5.0  1.0   \n",
       "3  0.005775 -2.726153  2.891378 -0.038325  2.280847  1.761478  3.0  3.0   \n",
       "4  0.044396  2.803576 -1.923381 -0.116657 -1.574199  6.098627  3.0  1.0   \n",
       "\n",
       "          x8         x9  ...       x116  x117  x118      x119      x120  \\\n",
       "0  -4.476051  -1.472306  ...   4.607926  52.0   1.0  0.773809  0.766531   \n",
       "1  -0.387076  -0.664552  ...  15.889763  53.0   1.0  7.065852  0.994304   \n",
       "2  -0.850146  -4.011487  ...  13.770410  53.0   1.0 -8.598553 -2.958302   \n",
       "3   9.116188  -4.610151  ...   5.904901  50.0   1.0  8.194975 -7.798308   \n",
       "4 -13.956141  13.785099  ... -14.603703  47.0   0.0  2.330789 -8.249825   \n",
       "\n",
       "        x121       x122       x123      x124  y  \n",
       "0   6.307142   9.074515  -2.694049  0.330964  0  \n",
       "1  -0.028411 -21.472850   5.626095  1.293455  0  \n",
       "2 -12.784030 -36.855873   0.356093  1.499790  0  \n",
       "3  10.910515  15.226094 -10.440813 -0.735116  0  \n",
       "4 -12.680490  40.192302  -5.037065  1.679262  1  \n",
       "\n",
       "[5 rows x 126 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dee8f910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x116</th>\n",
       "      <th>x117</th>\n",
       "      <th>x118</th>\n",
       "      <th>x119</th>\n",
       "      <th>x120</th>\n",
       "      <th>x121</th>\n",
       "      <th>x122</th>\n",
       "      <th>x123</th>\n",
       "      <th>x124</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.403735</td>\n",
       "      <td>-1.966104</td>\n",
       "      <td>-1.322339</td>\n",
       "      <td>0.084642</td>\n",
       "      <td>2.481997</td>\n",
       "      <td>-1.719155</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-11.546670</td>\n",
       "      <td>-7.073770</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.765934</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.897690</td>\n",
       "      <td>5.694125</td>\n",
       "      <td>-6.734618</td>\n",
       "      <td>17.052251</td>\n",
       "      <td>3.601040</td>\n",
       "      <td>2.873498</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.032128</td>\n",
       "      <td>6.516294</td>\n",
       "      <td>-0.939752</td>\n",
       "      <td>0.026937</td>\n",
       "      <td>-0.992999</td>\n",
       "      <td>5.995462</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-5.634876</td>\n",
       "      <td>1.937998</td>\n",
       "      <td>...</td>\n",
       "      <td>15.667015</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.781887</td>\n",
       "      <td>9.752716</td>\n",
       "      <td>5.918369</td>\n",
       "      <td>15.922908</td>\n",
       "      <td>5.460557</td>\n",
       "      <td>10.475816</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.280345</td>\n",
       "      <td>0.930291</td>\n",
       "      <td>-1.028828</td>\n",
       "      <td>-0.050924</td>\n",
       "      <td>-3.164733</td>\n",
       "      <td>6.885108</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.609005</td>\n",
       "      <td>-1.812488</td>\n",
       "      <td>...</td>\n",
       "      <td>8.523648</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.815214</td>\n",
       "      <td>-3.325532</td>\n",
       "      <td>4.123546</td>\n",
       "      <td>-19.656038</td>\n",
       "      <td>8.380318</td>\n",
       "      <td>-1.203315</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.313420</td>\n",
       "      <td>-0.568857</td>\n",
       "      <td>-1.576051</td>\n",
       "      <td>-0.003607</td>\n",
       "      <td>5.539969</td>\n",
       "      <td>-1.594770</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-11.517734</td>\n",
       "      <td>-5.364282</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.912115</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.158137</td>\n",
       "      <td>-7.088875</td>\n",
       "      <td>-3.035983</td>\n",
       "      <td>34.277048</td>\n",
       "      <td>-3.169203</td>\n",
       "      <td>1.417681</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.108825</td>\n",
       "      <td>-4.815631</td>\n",
       "      <td>5.491084</td>\n",
       "      <td>-0.123928</td>\n",
       "      <td>-1.932024</td>\n",
       "      <td>4.014821</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-3.117576</td>\n",
       "      <td>2.004889</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.432712</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.867657</td>\n",
       "      <td>-13.308519</td>\n",
       "      <td>1.008302</td>\n",
       "      <td>41.449381</td>\n",
       "      <td>-0.804560</td>\n",
       "      <td>-0.649453</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 126 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         x0        x1        x2        x3        x4        x5   x6   x7  \\\n",
       "0  0.403735 -1.966104 -1.322339  0.084642  2.481997 -1.719155  5.0  2.0   \n",
       "1  0.032128  6.516294 -0.939752  0.026937 -0.992999  5.995462  4.0  3.0   \n",
       "2 -0.280345  0.930291 -1.028828 -0.050924 -3.164733  6.885108  3.0  2.0   \n",
       "3 -0.313420 -0.568857 -1.576051 -0.003607  5.539969 -1.594770  4.0  3.0   \n",
       "4  0.108825 -4.815631  5.491084 -0.123928 -1.932024  4.014821  5.0  3.0   \n",
       "\n",
       "          x8        x9  ...       x116  x117  x118      x119       x120  \\\n",
       "0 -11.546670 -7.073770  ...  -7.765934  59.0   1.0 -9.897690   5.694125   \n",
       "1  -5.634876  1.937998  ...  15.667015  47.0   1.0  7.781887   9.752716   \n",
       "2   1.609005 -1.812488  ...   8.523648  55.0   0.0  6.815214  -3.325532   \n",
       "3 -11.517734 -5.364282  ... -13.912115  41.0   0.0  3.158137  -7.088875   \n",
       "4  -3.117576  2.004889  ... -14.432712  52.0   0.0 -3.867657 -13.308519   \n",
       "\n",
       "       x121       x122      x123       x124  y  \n",
       "0 -6.734618  17.052251  3.601040   2.873498  0  \n",
       "1  5.918369  15.922908  5.460557  10.475816  0  \n",
       "2  4.123546 -19.656038  8.380318  -1.203315  0  \n",
       "3 -3.035983  34.277048 -3.169203   1.417681  0  \n",
       "4  1.008302  41.449381 -0.804560  -0.649453  0  \n",
       "\n",
       "[5 rows x 126 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fed6702f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 126)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e050644",
   "metadata": {},
   "source": [
    "There are 100,000 rows of data with 126 attributes (125 independent variables and 1 dependent variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b6baef",
   "metadata": {},
   "source": [
    "### 1.2. Identify missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3853c19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x0      123\n",
       "x1      131\n",
       "x2      124\n",
       "x3      115\n",
       "x4      137\n",
       "       ... \n",
       "x121    129\n",
       "x122    127\n",
       "x123    130\n",
       "x124    123\n",
       "y         0\n",
       "Length: 126, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96d5d99",
   "metadata": {},
   "source": [
    "There are quite a larga number of missing values for each independent variables. In this case, DT/ensemble algorithms can handle missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5162807a",
   "metadata": {},
   "source": [
    "### 1.3. Data type checking and transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70647903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x0      float64\n",
       "x1      float64\n",
       "x2      float64\n",
       "x3      float64\n",
       "x4      float64\n",
       "         ...   \n",
       "x121    float64\n",
       "x122    float64\n",
       "x123    float64\n",
       "x124    float64\n",
       "y         int64\n",
       "Length: 126, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9417ef69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x21', 'x79', 'x89', 'x108', 'x112']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_to_encode = list(df_train.select_dtypes(include = ['object']).columns)\n",
    "features_to_encode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b78808b",
   "metadata": {},
   "source": [
    "Independent variable x21, x79, x89, x108, x112 have the type of object. Therefore we need to transform this to numerical representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bde9c137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x21\n",
    "x21_unique = df_train['x21'].unique()\n",
    "x21_d = {}\n",
    "for idx,val in enumerate(x21_unique):\n",
    "    x21_d[val]=idx\n",
    "df_train['x21'] = df_train['x21'].map(x21_d)\n",
    "df_test['x21'] = df_test['x21'].map(x21_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "685668d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    1\n",
       "3    0\n",
       "4    1\n",
       "Name: x21, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['x21'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "946bc971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    0\n",
       "3    5\n",
       "4    8\n",
       "Name: x21, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['x21'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d5e2382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x79\n",
    "x79_unique = df_train['x79'].unique()\n",
    "x79_d = {}\n",
    "for idx,val in enumerate(x79_unique):\n",
    "    x79_d[val]=idx\n",
    "df_train['x79'] = df_train['x79'].map(x79_d)\n",
    "df_test['x79'] = df_test['x79'].map(x79_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55baab4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    1\n",
       "3    0\n",
       "4    0\n",
       "Name: x79, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['x79'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35ff4bb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    1\n",
       "4    1\n",
       "Name: x79, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['x79'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f7cd212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x89\n",
    "x89_unique = df_train['x89'].unique()\n",
    "x89_d = {}\n",
    "for idx,val in enumerate(x89_unique):\n",
    "    x89_d[val]=idx\n",
    "df_train['x89'] = df_train['x89'].map(x89_d)\n",
    "df_test['x89'] = df_test['x89'].map(x89_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8d9523ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    2\n",
       "3    3\n",
       "4    3\n",
       "Name: x89, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['x89'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3f198d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     7\n",
       "1     8\n",
       "2     7\n",
       "3     0\n",
       "4    11\n",
       "Name: x89, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['x89'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6d89d3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x108\n",
    "x108_unique = df_train['x108'].unique()\n",
    "x108_d = {}\n",
    "for idx,val in enumerate(x108_unique):\n",
    "    x108_d[val]=idx\n",
    "df_train['x108'] = df_train['x108'].map(x108_d)\n",
    "df_test['x108'] = df_test['x108'].map(x108_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b23f280f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    1\n",
       "3    0\n",
       "4    2\n",
       "Name: x108, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['x108'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "403f9d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: x108, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['x108'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "147a0eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x112\n",
    "x112_unique = df_train['x112'].unique()\n",
    "x112_d = {}\n",
    "for idx,val in enumerate(x112_unique):\n",
    "    x112_d[val]=idx\n",
    "df_train['x112'] = df_train['x112'].map(x112_d)\n",
    "df_test['x112'] = df_test['x112'].map(x112_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "67a17afa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    1\n",
       "3    2\n",
       "4    1\n",
       "Name: x112, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['x112'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "959f8ed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4\n",
       "1    2\n",
       "2    4\n",
       "3    1\n",
       "4    0\n",
       "Name: x112, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['x112'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1330f74",
   "metadata": {},
   "source": [
    "### 1.4. Splitting datasets to X (independent variables) and y (dependent variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "745e9b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>List of features: ['x0', 'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10', 'x11', 'x12', 'x13', 'x14', 'x15', 'x16', 'x17', 'x18', 'x19', 'x20', 'x21', 'x22', 'x23', 'x24', 'x25', 'x26', 'x27', 'x28', 'x29', 'x30', 'x31', 'x32', 'x33', 'x34', 'x35', 'x36', 'x37', 'x38', 'x39', 'x40', 'x41', 'x42', 'x43', 'x44', 'x45', 'x46', 'x47', 'x48', 'x49', 'x50', 'x51', 'x52', 'x53', 'x54', 'x55', 'x56', 'x57', 'x58', 'x59', 'x60', 'x61', 'x62', 'x63', 'x64', 'x65', 'x66', 'x67', 'x68', 'x69', 'x70', 'x71', 'x72', 'x73', 'x74', 'x75', 'x76', 'x77', 'x78', 'x79', 'x80', 'x81', 'x82', 'x83', 'x84', 'x85', 'x86', 'x87', 'x88', 'x89', 'x90', 'x91', 'x92', 'x93', 'x94', 'x95', 'x96', 'x97', 'x98', 'x99', 'x100', 'x101', 'x102', 'x103', 'x104', 'x105', 'x106', 'x107', 'x108', 'x109', 'x110', 'x111', 'x112', 'x113', 'x114', 'x115', 'x116', 'x117', 'x118', 'x119', 'x120', 'x121', 'x122', 'x123', 'x124']\n",
      ">>Target: ['y']\n"
     ]
    }
   ],
   "source": [
    "attributes = list(df_train.columns)\n",
    "features = attributes[:-1]\n",
    "target = attributes[-1:]\n",
    "print(f\">>List of features: {features}\\n>>Target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d0246add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the datasets\n",
    "X_train = df_train[features].values\n",
    "y_train = df_train[target].values.flatten()\n",
    "X_test = df_test[features].values\n",
    "y_test = df_test[target].values.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb63283f",
   "metadata": {},
   "source": [
    "### 1.5. Imbalance data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b836c89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5497aa64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class=0, n=83008 (83.00800000000001%)\n",
      "Class=1, n=16992 (16.991999999999997%)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "counter = Counter(y_train)\n",
    "plt.bar(counter.keys(), counter.values())\n",
    "for k, v in counter.items():\n",
    "    dist = v/len(y_train) * 100\n",
    "    print(f\"Class={k}, n={v} ({dist}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82fac37",
   "metadata": {},
   "source": [
    "It can be seen that ~83% of the data is in class 0 and the remaining is in class 1. Therefore, sampling techniques will be performed to balance the data for each class. Oversampling will be used in this case (i.e., SMOTE and ADASYN) as well as Undersampling (i.e., RandomUnderSampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a83176",
   "metadata": {},
   "source": [
    "#### 1.5.1. SMOTE Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "17958dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE()\n",
    "# Drop NaN values\n",
    "df_train_nan_dropped = df_train[:].dropna()\n",
    "X_train_nan_dropped = df_train_nan_dropped[features].values\n",
    "y_train_nan_dropped = df_train_nan_dropped[target].values.flatten()\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_nan_dropped, y_train_nan_dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b0243157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class=0, n=70237 (50.0%)\n",
      "Class=1, n=70237 (50.0%)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "counter = Counter(y_train_smote)\n",
    "plt.bar(counter.keys(), counter.values())\n",
    "for k, v in counter.items():\n",
    "    dist = v/len(y_train_smote) * 100\n",
    "    print(f\"Class={k}, n={v} ({dist}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b30238",
   "metadata": {},
   "source": [
    "#### 1.5.2. ADASYN Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a309e324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class=0, n=70237 (50.90707467511288%)\n",
      "Class=1, n=67734 (49.09292532488712%)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "adasyn = ADASYN()\n",
    "X_train_ada, y_train_ada = adasyn.fit_resample(X_train_nan_dropped, y_train_nan_dropped)\n",
    "\n",
    "# Check how 'balanced' the dataset - target class - is after oversampling\n",
    "counter = Counter(y_train_ada)\n",
    "plt.bar(counter.keys(), counter.values())\n",
    "for k, v in counter.items():\n",
    "    dist = v/len(y_train_ada) * 100\n",
    "    print(f\"Class={k}, n={v} ({dist}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3746b72",
   "metadata": {},
   "source": [
    "#### 1.5.3. RandomUnderSampler Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5b482043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class=0, n=14388 (50.0%)\n",
      "Class=1, n=14388 (50.0%)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rus = RandomUnderSampler()\n",
    "X_train_rus, y_train_rus = rus.fit_resample(X_train_nan_dropped, y_train_nan_dropped)\n",
    "\n",
    "# Check how 'balanced' the dataset - target class - is after oversampling\n",
    "counter = Counter(y_train_rus)\n",
    "plt.bar(counter.keys(), counter.values())\n",
    "for k, v in counter.items():\n",
    "    dist = v/len(y_train_rus) * 100\n",
    "    print(f\"Class={k}, n={v} ({dist}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80f9bcc",
   "metadata": {},
   "source": [
    "We will perform experiments in training by using:\n",
    "1. the imbalanced dataset => X_train, y_train\n",
    "2. the oversampled dataset (SMOTE) => X_train_smote, y_train_smote\n",
    "3. the oversampled dataset (ADASYN) => X_train_ada, y_train_ada\n",
    "4. the undersampled dataset (RandomUnderSampler) => X_train_rus, y_train_rus\n",
    "\n",
    "PS: For sampled dataset, df_test containing NaN values will be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a830af35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_nan_dropped = df_test[:].dropna()\n",
    "X_test_nan_dropped = df_test_nan_dropped[features].values\n",
    "y_test_nan_dropped = df_test_nan_dropped[target].values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ddeaf574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21060, 126)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_nan_dropped.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a316a71e",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "87dd726c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x116</th>\n",
       "      <th>x117</th>\n",
       "      <th>x118</th>\n",
       "      <th>x119</th>\n",
       "      <th>x120</th>\n",
       "      <th>x121</th>\n",
       "      <th>x122</th>\n",
       "      <th>x123</th>\n",
       "      <th>x124</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>99877.000000</td>\n",
       "      <td>99869.000000</td>\n",
       "      <td>99876.000000</td>\n",
       "      <td>99885.000000</td>\n",
       "      <td>99863.000000</td>\n",
       "      <td>99884.000000</td>\n",
       "      <td>99878.000000</td>\n",
       "      <td>99867.000000</td>\n",
       "      <td>99866.000000</td>\n",
       "      <td>99870.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>99877.000000</td>\n",
       "      <td>99864.000000</td>\n",
       "      <td>99873.000000</td>\n",
       "      <td>99878.000000</td>\n",
       "      <td>99880.000000</td>\n",
       "      <td>99871.000000</td>\n",
       "      <td>99873.000000</td>\n",
       "      <td>99870.000000</td>\n",
       "      <td>99877.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.000110</td>\n",
       "      <td>0.001045</td>\n",
       "      <td>0.009028</td>\n",
       "      <td>-0.000254</td>\n",
       "      <td>-0.677076</td>\n",
       "      <td>-0.002404</td>\n",
       "      <td>4.306714</td>\n",
       "      <td>2.366517</td>\n",
       "      <td>0.013684</td>\n",
       "      <td>-0.016469</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038825</td>\n",
       "      <td>50.012697</td>\n",
       "      <td>0.577373</td>\n",
       "      <td>3.883003</td>\n",
       "      <td>-0.021634</td>\n",
       "      <td>-0.015191</td>\n",
       "      <td>7.594731</td>\n",
       "      <td>-0.012175</td>\n",
       "      <td>0.008854</td>\n",
       "      <td>0.169920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.424300</td>\n",
       "      <td>3.379969</td>\n",
       "      <td>3.088269</td>\n",
       "      <td>0.121542</td>\n",
       "      <td>2.561589</td>\n",
       "      <td>4.042530</td>\n",
       "      <td>1.140149</td>\n",
       "      <td>0.728027</td>\n",
       "      <td>7.766165</td>\n",
       "      <td>5.391990</td>\n",
       "      <td>...</td>\n",
       "      <td>9.063181</td>\n",
       "      <td>6.892136</td>\n",
       "      <td>0.493980</td>\n",
       "      <td>10.795317</td>\n",
       "      <td>5.571357</td>\n",
       "      <td>9.745984</td>\n",
       "      <td>35.358657</td>\n",
       "      <td>3.947540</td>\n",
       "      <td>4.128462</td>\n",
       "      <td>0.375564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.724571</td>\n",
       "      <td>-16.097070</td>\n",
       "      <td>-13.519334</td>\n",
       "      <td>-0.517647</td>\n",
       "      <td>-13.627396</td>\n",
       "      <td>-16.984482</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-34.513401</td>\n",
       "      <td>-23.449782</td>\n",
       "      <td>...</td>\n",
       "      <td>-37.320446</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-42.113882</td>\n",
       "      <td>-23.512064</td>\n",
       "      <td>-43.961674</td>\n",
       "      <td>-165.068134</td>\n",
       "      <td>-17.229400</td>\n",
       "      <td>-16.394975</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.288149</td>\n",
       "      <td>-2.274297</td>\n",
       "      <td>-2.070010</td>\n",
       "      <td>-0.082583</td>\n",
       "      <td>-2.384499</td>\n",
       "      <td>-2.732918</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-5.233073</td>\n",
       "      <td>-3.642062</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.077436</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.247750</td>\n",
       "      <td>-3.776839</td>\n",
       "      <td>-6.630953</td>\n",
       "      <td>-16.275026</td>\n",
       "      <td>-2.656104</td>\n",
       "      <td>-2.766022</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.000976</td>\n",
       "      <td>0.015052</td>\n",
       "      <td>0.014444</td>\n",
       "      <td>-0.000445</td>\n",
       "      <td>-0.679873</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.004569</td>\n",
       "      <td>-0.034581</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044680</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.900552</td>\n",
       "      <td>-0.018491</td>\n",
       "      <td>-0.025400</td>\n",
       "      <td>6.668708</td>\n",
       "      <td>-0.032674</td>\n",
       "      <td>-0.002028</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.286196</td>\n",
       "      <td>2.288710</td>\n",
       "      <td>2.087186</td>\n",
       "      <td>0.081461</td>\n",
       "      <td>1.034269</td>\n",
       "      <td>2.726788</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.273118</td>\n",
       "      <td>3.617453</td>\n",
       "      <td>...</td>\n",
       "      <td>6.144167</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.039607</td>\n",
       "      <td>3.743165</td>\n",
       "      <td>6.594418</td>\n",
       "      <td>30.879552</td>\n",
       "      <td>2.638333</td>\n",
       "      <td>2.788782</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.762542</td>\n",
       "      <td>14.768077</td>\n",
       "      <td>13.335437</td>\n",
       "      <td>0.513763</td>\n",
       "      <td>10.442234</td>\n",
       "      <td>20.186745</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>33.000825</td>\n",
       "      <td>23.296840</td>\n",
       "      <td>...</td>\n",
       "      <td>38.712294</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>57.003256</td>\n",
       "      <td>25.927916</td>\n",
       "      <td>41.261627</td>\n",
       "      <td>174.645087</td>\n",
       "      <td>17.058603</td>\n",
       "      <td>17.921770</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 126 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 x0            x1            x2            x3            x4  \\\n",
       "count  99877.000000  99869.000000  99876.000000  99885.000000  99863.000000   \n",
       "mean      -0.000110      0.001045      0.009028     -0.000254     -0.677076   \n",
       "std        0.424300      3.379969      3.088269      0.121542      2.561589   \n",
       "min       -1.724571    -16.097070    -13.519334     -0.517647    -13.627396   \n",
       "25%       -0.288149     -2.274297     -2.070010     -0.082583     -2.384499   \n",
       "50%       -0.000976      0.015052      0.014444     -0.000445     -0.679873   \n",
       "75%        0.286196      2.288710      2.087186      0.081461      1.034269   \n",
       "max        1.762542     14.768077     13.335437      0.513763     10.442234   \n",
       "\n",
       "                 x5            x6            x7            x8            x9  \\\n",
       "count  99884.000000  99878.000000  99867.000000  99866.000000  99870.000000   \n",
       "mean      -0.002404      4.306714      2.366517      0.013684     -0.016469   \n",
       "std        4.042530      1.140149      0.728027      7.766165      5.391990   \n",
       "min      -16.984482      0.000000      0.000000    -34.513401    -23.449782   \n",
       "25%       -2.732918      4.000000      2.000000     -5.233073     -3.642062   \n",
       "50%        0.000063      4.000000      2.000000      0.004569     -0.034581   \n",
       "75%        2.726788      5.000000      3.000000      5.273118      3.617453   \n",
       "max       20.186745      9.000000      5.000000     33.000825     23.296840   \n",
       "\n",
       "       ...          x116          x117          x118          x119  \\\n",
       "count  ...  99877.000000  99864.000000  99873.000000  99878.000000   \n",
       "mean   ...      0.038825     50.012697      0.577373      3.883003   \n",
       "std    ...      9.063181      6.892136      0.493980     10.795317   \n",
       "min    ...    -37.320446     21.000000      0.000000    -42.113882   \n",
       "25%    ...     -6.077436     45.000000      0.000000     -3.247750   \n",
       "50%    ...      0.044680     50.000000      1.000000      3.900552   \n",
       "75%    ...      6.144167     54.000000      1.000000     11.039607   \n",
       "max    ...     38.712294     80.000000      1.000000     57.003256   \n",
       "\n",
       "               x120          x121          x122          x123          x124  \\\n",
       "count  99880.000000  99871.000000  99873.000000  99870.000000  99877.000000   \n",
       "mean      -0.021634     -0.015191      7.594731     -0.012175      0.008854   \n",
       "std        5.571357      9.745984     35.358657      3.947540      4.128462   \n",
       "min      -23.512064    -43.961674   -165.068134    -17.229400    -16.394975   \n",
       "25%       -3.776839     -6.630953    -16.275026     -2.656104     -2.766022   \n",
       "50%       -0.018491     -0.025400      6.668708     -0.032674     -0.002028   \n",
       "75%        3.743165      6.594418     30.879552      2.638333      2.788782   \n",
       "max       25.927916     41.261627    174.645087     17.058603     17.921770   \n",
       "\n",
       "                   y  \n",
       "count  100000.000000  \n",
       "mean        0.169920  \n",
       "std         0.375564  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 126 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the summary statistics of the given dataset\n",
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b6b35a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x116</th>\n",
       "      <th>x117</th>\n",
       "      <th>x118</th>\n",
       "      <th>x119</th>\n",
       "      <th>x120</th>\n",
       "      <th>x121</th>\n",
       "      <th>x122</th>\n",
       "      <th>x123</th>\n",
       "      <th>x124</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>84625.000000</td>\n",
       "      <td>84625.000000</td>\n",
       "      <td>84625.000000</td>\n",
       "      <td>84625.000000</td>\n",
       "      <td>84625.000000</td>\n",
       "      <td>84625.000000</td>\n",
       "      <td>84625.000000</td>\n",
       "      <td>84625.000000</td>\n",
       "      <td>84625.000000</td>\n",
       "      <td>84625.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>84625.000000</td>\n",
       "      <td>84625.000000</td>\n",
       "      <td>84625.000000</td>\n",
       "      <td>84625.000000</td>\n",
       "      <td>84625.000000</td>\n",
       "      <td>84625.000000</td>\n",
       "      <td>84625.000000</td>\n",
       "      <td>84625.000000</td>\n",
       "      <td>84625.000000</td>\n",
       "      <td>84625.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000134</td>\n",
       "      <td>-0.005367</td>\n",
       "      <td>0.012730</td>\n",
       "      <td>-0.000499</td>\n",
       "      <td>-0.679438</td>\n",
       "      <td>-0.000102</td>\n",
       "      <td>4.305855</td>\n",
       "      <td>2.367244</td>\n",
       "      <td>0.016531</td>\n",
       "      <td>-0.020500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051632</td>\n",
       "      <td>50.008815</td>\n",
       "      <td>0.577229</td>\n",
       "      <td>3.884232</td>\n",
       "      <td>-0.026894</td>\n",
       "      <td>0.008140</td>\n",
       "      <td>7.594259</td>\n",
       "      <td>-0.008721</td>\n",
       "      <td>0.006708</td>\n",
       "      <td>0.170021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.424150</td>\n",
       "      <td>3.382031</td>\n",
       "      <td>3.089167</td>\n",
       "      <td>0.121762</td>\n",
       "      <td>2.562778</td>\n",
       "      <td>4.037325</td>\n",
       "      <td>1.139768</td>\n",
       "      <td>0.728401</td>\n",
       "      <td>7.777533</td>\n",
       "      <td>5.385425</td>\n",
       "      <td>...</td>\n",
       "      <td>9.064099</td>\n",
       "      <td>6.903307</td>\n",
       "      <td>0.494003</td>\n",
       "      <td>10.809025</td>\n",
       "      <td>5.576218</td>\n",
       "      <td>9.743352</td>\n",
       "      <td>35.432185</td>\n",
       "      <td>3.955279</td>\n",
       "      <td>4.132098</td>\n",
       "      <td>0.375653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.724571</td>\n",
       "      <td>-16.097070</td>\n",
       "      <td>-13.519334</td>\n",
       "      <td>-0.517647</td>\n",
       "      <td>-13.627396</td>\n",
       "      <td>-16.984482</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-34.513401</td>\n",
       "      <td>-21.393586</td>\n",
       "      <td>...</td>\n",
       "      <td>-37.320446</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-42.113882</td>\n",
       "      <td>-23.512064</td>\n",
       "      <td>-42.803538</td>\n",
       "      <td>-165.068134</td>\n",
       "      <td>-17.229400</td>\n",
       "      <td>-16.394975</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.288439</td>\n",
       "      <td>-2.277408</td>\n",
       "      <td>-2.066637</td>\n",
       "      <td>-0.083161</td>\n",
       "      <td>-2.384102</td>\n",
       "      <td>-2.719394</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-5.231273</td>\n",
       "      <td>-3.653562</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.056929</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.242579</td>\n",
       "      <td>-3.794949</td>\n",
       "      <td>-6.618319</td>\n",
       "      <td>-16.313432</td>\n",
       "      <td>-2.657868</td>\n",
       "      <td>-2.770613</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.000575</td>\n",
       "      <td>0.015830</td>\n",
       "      <td>0.022342</td>\n",
       "      <td>-0.000690</td>\n",
       "      <td>-0.683342</td>\n",
       "      <td>0.008073</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.008370</td>\n",
       "      <td>-0.043343</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046831</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.898811</td>\n",
       "      <td>-0.024713</td>\n",
       "      <td>-0.014172</td>\n",
       "      <td>6.669958</td>\n",
       "      <td>-0.028475</td>\n",
       "      <td>-0.008476</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.286555</td>\n",
       "      <td>2.282198</td>\n",
       "      <td>2.097138</td>\n",
       "      <td>0.081502</td>\n",
       "      <td>1.033504</td>\n",
       "      <td>2.719203</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.285481</td>\n",
       "      <td>3.603270</td>\n",
       "      <td>...</td>\n",
       "      <td>6.160476</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.038551</td>\n",
       "      <td>3.745235</td>\n",
       "      <td>6.652677</td>\n",
       "      <td>30.897783</td>\n",
       "      <td>2.646747</td>\n",
       "      <td>2.788143</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.714387</td>\n",
       "      <td>14.768077</td>\n",
       "      <td>13.335437</td>\n",
       "      <td>0.513763</td>\n",
       "      <td>10.442234</td>\n",
       "      <td>20.186745</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>31.449940</td>\n",
       "      <td>23.296840</td>\n",
       "      <td>...</td>\n",
       "      <td>38.141106</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>57.003256</td>\n",
       "      <td>25.927916</td>\n",
       "      <td>41.261627</td>\n",
       "      <td>174.645087</td>\n",
       "      <td>17.058603</td>\n",
       "      <td>17.921770</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 126 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 x0            x1            x2            x3            x4  \\\n",
       "count  84625.000000  84625.000000  84625.000000  84625.000000  84625.000000   \n",
       "mean       0.000134     -0.005367      0.012730     -0.000499     -0.679438   \n",
       "std        0.424150      3.382031      3.089167      0.121762      2.562778   \n",
       "min       -1.724571    -16.097070    -13.519334     -0.517647    -13.627396   \n",
       "25%       -0.288439     -2.277408     -2.066637     -0.083161     -2.384102   \n",
       "50%       -0.000575      0.015830      0.022342     -0.000690     -0.683342   \n",
       "75%        0.286555      2.282198      2.097138      0.081502      1.033504   \n",
       "max        1.714387     14.768077     13.335437      0.513763     10.442234   \n",
       "\n",
       "                 x5            x6            x7            x8            x9  \\\n",
       "count  84625.000000  84625.000000  84625.000000  84625.000000  84625.000000   \n",
       "mean      -0.000102      4.305855      2.367244      0.016531     -0.020500   \n",
       "std        4.037325      1.139768      0.728401      7.777533      5.385425   \n",
       "min      -16.984482      0.000000      0.000000    -34.513401    -21.393586   \n",
       "25%       -2.719394      4.000000      2.000000     -5.231273     -3.653562   \n",
       "50%        0.008073      4.000000      2.000000      0.008370     -0.043343   \n",
       "75%        2.719203      5.000000      3.000000      5.285481      3.603270   \n",
       "max       20.186745      9.000000      5.000000     31.449940     23.296840   \n",
       "\n",
       "       ...          x116          x117          x118          x119  \\\n",
       "count  ...  84625.000000  84625.000000  84625.000000  84625.000000   \n",
       "mean   ...      0.051632     50.008815      0.577229      3.884232   \n",
       "std    ...      9.064099      6.903307      0.494003     10.809025   \n",
       "min    ...    -37.320446     22.000000      0.000000    -42.113882   \n",
       "25%    ...     -6.056929     45.000000      0.000000     -3.242579   \n",
       "50%    ...      0.046831     50.000000      1.000000      3.898811   \n",
       "75%    ...      6.160476     54.000000      1.000000     11.038551   \n",
       "max    ...     38.141106     80.000000      1.000000     57.003256   \n",
       "\n",
       "               x120          x121          x122          x123          x124  \\\n",
       "count  84625.000000  84625.000000  84625.000000  84625.000000  84625.000000   \n",
       "mean      -0.026894      0.008140      7.594259     -0.008721      0.006708   \n",
       "std        5.576218      9.743352     35.432185      3.955279      4.132098   \n",
       "min      -23.512064    -42.803538   -165.068134    -17.229400    -16.394975   \n",
       "25%       -3.794949     -6.618319    -16.313432     -2.657868     -2.770613   \n",
       "50%       -0.024713     -0.014172      6.669958     -0.028475     -0.008476   \n",
       "75%        3.745235      6.652677     30.897783      2.646747      2.788143   \n",
       "max       25.927916     41.261627    174.645087     17.058603     17.921770   \n",
       "\n",
       "                  y  \n",
       "count  84625.000000  \n",
       "mean       0.170021  \n",
       "std        0.375653  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 126 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the summary statistics of the given dataset (NaN dropped)\n",
    "df_train_nan_dropped.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cc347e",
   "metadata": {},
   "source": [
    "It can be seen the data with dropped nan values is reduced from 100,000 rows to 84,625 rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935b30b3",
   "metadata": {},
   "source": [
    "### 2.1. Correlation Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5ad1b901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaN values not dropped\n",
    "df_train_corr = df_train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a74f313b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x116</th>\n",
       "      <th>x117</th>\n",
       "      <th>x118</th>\n",
       "      <th>x119</th>\n",
       "      <th>x120</th>\n",
       "      <th>x121</th>\n",
       "      <th>x122</th>\n",
       "      <th>x123</th>\n",
       "      <th>x124</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.000851</td>\n",
       "      <td>-0.001769</td>\n",
       "      <td>-0.003981</td>\n",
       "      <td>0.004158</td>\n",
       "      <td>-0.002562</td>\n",
       "      <td>-0.002733</td>\n",
       "      <td>0.002988</td>\n",
       "      <td>-0.000337</td>\n",
       "      <td>0.005547</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002329</td>\n",
       "      <td>-0.001543</td>\n",
       "      <td>-0.001810</td>\n",
       "      <td>-0.000421</td>\n",
       "      <td>0.001778</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.002149</td>\n",
       "      <td>0.003763</td>\n",
       "      <td>0.002547</td>\n",
       "      <td>-0.001644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1</th>\n",
       "      <td>-0.000851</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.005267</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>-0.001632</td>\n",
       "      <td>0.003393</td>\n",
       "      <td>0.003063</td>\n",
       "      <td>0.005959</td>\n",
       "      <td>-0.006401</td>\n",
       "      <td>-0.003348</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000925</td>\n",
       "      <td>-0.001786</td>\n",
       "      <td>-0.002230</td>\n",
       "      <td>-0.000263</td>\n",
       "      <td>-0.000645</td>\n",
       "      <td>-0.006180</td>\n",
       "      <td>0.002637</td>\n",
       "      <td>-0.003784</td>\n",
       "      <td>0.001868</td>\n",
       "      <td>-0.002780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x2</th>\n",
       "      <td>-0.001769</td>\n",
       "      <td>-0.005267</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001796</td>\n",
       "      <td>-0.001360</td>\n",
       "      <td>0.000311</td>\n",
       "      <td>-0.002994</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.004945</td>\n",
       "      <td>-0.000670</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>0.002983</td>\n",
       "      <td>-0.002159</td>\n",
       "      <td>-0.003031</td>\n",
       "      <td>-0.002310</td>\n",
       "      <td>-0.003096</td>\n",
       "      <td>0.003399</td>\n",
       "      <td>-0.002596</td>\n",
       "      <td>-0.001971</td>\n",
       "      <td>-0.000664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x3</th>\n",
       "      <td>-0.003981</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.001796</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.000927</td>\n",
       "      <td>0.001838</td>\n",
       "      <td>-0.002631</td>\n",
       "      <td>0.001262</td>\n",
       "      <td>0.000837</td>\n",
       "      <td>0.003774</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001051</td>\n",
       "      <td>0.001175</td>\n",
       "      <td>-0.003233</td>\n",
       "      <td>-0.002328</td>\n",
       "      <td>-0.002479</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.002679</td>\n",
       "      <td>-0.003049</td>\n",
       "      <td>-0.003161</td>\n",
       "      <td>0.001639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x4</th>\n",
       "      <td>0.004158</td>\n",
       "      <td>-0.001632</td>\n",
       "      <td>-0.001360</td>\n",
       "      <td>-0.000927</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003981</td>\n",
       "      <td>-0.002251</td>\n",
       "      <td>-0.001737</td>\n",
       "      <td>0.002565</td>\n",
       "      <td>-0.001022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002183</td>\n",
       "      <td>-0.191762</td>\n",
       "      <td>0.280648</td>\n",
       "      <td>-0.155789</td>\n",
       "      <td>0.002526</td>\n",
       "      <td>0.001988</td>\n",
       "      <td>-0.019127</td>\n",
       "      <td>-0.001366</td>\n",
       "      <td>-0.004206</td>\n",
       "      <td>0.007267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x121</th>\n",
       "      <td>0.000240</td>\n",
       "      <td>-0.006180</td>\n",
       "      <td>-0.003096</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.001988</td>\n",
       "      <td>-0.005344</td>\n",
       "      <td>-0.001901</td>\n",
       "      <td>-0.000597</td>\n",
       "      <td>-0.002660</td>\n",
       "      <td>-0.002376</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000291</td>\n",
       "      <td>0.003752</td>\n",
       "      <td>0.003308</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.004481</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>-0.005440</td>\n",
       "      <td>-0.001313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x122</th>\n",
       "      <td>0.002149</td>\n",
       "      <td>0.002637</td>\n",
       "      <td>0.003399</td>\n",
       "      <td>0.002679</td>\n",
       "      <td>-0.019127</td>\n",
       "      <td>-0.003970</td>\n",
       "      <td>0.005172</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>-0.002291</td>\n",
       "      <td>0.003621</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>-0.607116</td>\n",
       "      <td>-0.059400</td>\n",
       "      <td>0.372855</td>\n",
       "      <td>-0.004688</td>\n",
       "      <td>-0.004481</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.007807</td>\n",
       "      <td>-0.003068</td>\n",
       "      <td>-0.041442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x123</th>\n",
       "      <td>0.003763</td>\n",
       "      <td>-0.003784</td>\n",
       "      <td>-0.002596</td>\n",
       "      <td>-0.003049</td>\n",
       "      <td>-0.001366</td>\n",
       "      <td>0.001125</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.003072</td>\n",
       "      <td>-0.000046</td>\n",
       "      <td>0.001827</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007059</td>\n",
       "      <td>0.005614</td>\n",
       "      <td>0.002366</td>\n",
       "      <td>-0.001437</td>\n",
       "      <td>0.002980</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>-0.007807</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.000666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x124</th>\n",
       "      <td>0.002547</td>\n",
       "      <td>0.001868</td>\n",
       "      <td>-0.001971</td>\n",
       "      <td>-0.003161</td>\n",
       "      <td>-0.004206</td>\n",
       "      <td>-0.000228</td>\n",
       "      <td>0.002808</td>\n",
       "      <td>-0.003338</td>\n",
       "      <td>0.004651</td>\n",
       "      <td>0.001572</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003675</td>\n",
       "      <td>0.004731</td>\n",
       "      <td>0.000946</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>-0.000587</td>\n",
       "      <td>-0.005440</td>\n",
       "      <td>-0.003068</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.002676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>-0.001644</td>\n",
       "      <td>-0.002780</td>\n",
       "      <td>-0.000664</td>\n",
       "      <td>0.001639</td>\n",
       "      <td>0.007267</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>-0.003780</td>\n",
       "      <td>-0.005546</td>\n",
       "      <td>-0.002241</td>\n",
       "      <td>-0.006534</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001443</td>\n",
       "      <td>0.052421</td>\n",
       "      <td>0.067032</td>\n",
       "      <td>-0.080113</td>\n",
       "      <td>0.002461</td>\n",
       "      <td>-0.001313</td>\n",
       "      <td>-0.041442</td>\n",
       "      <td>-0.000666</td>\n",
       "      <td>-0.002676</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>126 rows × 126 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            x0        x1        x2        x3        x4        x5        x6  \\\n",
       "x0    1.000000 -0.000851 -0.001769 -0.003981  0.004158 -0.002562 -0.002733   \n",
       "x1   -0.000851  1.000000 -0.005267  0.000171 -0.001632  0.003393  0.003063   \n",
       "x2   -0.001769 -0.005267  1.000000  0.001796 -0.001360  0.000311 -0.002994   \n",
       "x3   -0.003981  0.000171  0.001796  1.000000 -0.000927  0.001838 -0.002631   \n",
       "x4    0.004158 -0.001632 -0.001360 -0.000927  1.000000  0.003981 -0.002251   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "x121  0.000240 -0.006180 -0.003096  0.000531  0.001988 -0.005344 -0.001901   \n",
       "x122  0.002149  0.002637  0.003399  0.002679 -0.019127 -0.003970  0.005172   \n",
       "x123  0.003763 -0.003784 -0.002596 -0.003049 -0.001366  0.001125  0.000313   \n",
       "x124  0.002547  0.001868 -0.001971 -0.003161 -0.004206 -0.000228  0.002808   \n",
       "y    -0.001644 -0.002780 -0.000664  0.001639  0.007267  0.000705 -0.003780   \n",
       "\n",
       "            x7        x8        x9  ...      x116      x117      x118  \\\n",
       "x0    0.002988 -0.000337  0.005547  ... -0.002329 -0.001543 -0.001810   \n",
       "x1    0.005959 -0.006401 -0.003348  ...  0.000925 -0.001786 -0.002230   \n",
       "x2    0.000408  0.004945 -0.000670  ... -0.000236  0.002983 -0.002159   \n",
       "x3    0.001262  0.000837  0.003774  ...  0.001051  0.001175 -0.003233   \n",
       "x4   -0.001737  0.002565 -0.001022  ...  0.002183 -0.191762  0.280648   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "x121 -0.000597 -0.002660 -0.002376  ... -0.000291  0.003752  0.003308   \n",
       "x122  0.000299 -0.002291  0.003621  ...  0.002412 -0.607116 -0.059400   \n",
       "x123  0.003072 -0.000046  0.001827  ... -0.007059  0.005614  0.002366   \n",
       "x124 -0.003338  0.004651  0.001572  ...  0.003675  0.004731  0.000946   \n",
       "y    -0.005546 -0.002241 -0.006534  ... -0.001443  0.052421  0.067032   \n",
       "\n",
       "          x119      x120      x121      x122      x123      x124         y  \n",
       "x0   -0.000421  0.001778  0.000240  0.002149  0.003763  0.002547 -0.001644  \n",
       "x1   -0.000263 -0.000645 -0.006180  0.002637 -0.003784  0.001868 -0.002780  \n",
       "x2   -0.003031 -0.002310 -0.003096  0.003399 -0.002596 -0.001971 -0.000664  \n",
       "x3   -0.002328 -0.002479  0.000531  0.002679 -0.003049 -0.003161  0.001639  \n",
       "x4   -0.155789  0.002526  0.001988 -0.019127 -0.001366 -0.004206  0.007267  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "x121  0.000178  0.001130  1.000000 -0.004481  0.000072 -0.005440 -0.001313  \n",
       "x122  0.372855 -0.004688 -0.004481  1.000000 -0.007807 -0.003068 -0.041442  \n",
       "x123 -0.001437  0.002980  0.000072 -0.007807  1.000000  0.004455 -0.000666  \n",
       "x124  0.001266 -0.000587 -0.005440 -0.003068  0.004455  1.000000 -0.002676  \n",
       "y    -0.080113  0.002461 -0.001313 -0.041442 -0.000666 -0.002676  1.000000  \n",
       "\n",
       "[126 rows x 126 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "eba88037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_train_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6e985976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_corr_to_y = df_train_corr['y']\n",
    "# type(df_train_corr_to_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8dd759",
   "metadata": {},
   "source": [
    "#### 2.1.1 Get variables with strong correlation with target variable y (strong positive and strong negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fa0dcd",
   "metadata": {},
   "source": [
    "Strong negative correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8fe56e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x57    -0.128242\n",
       "x41    -0.120998\n",
       "x60    -0.113804\n",
       "x44    -0.097781\n",
       "x105   -0.094995\n",
       "x67    -0.083999\n",
       "x119   -0.080113\n",
       "x61    -0.075836\n",
       "x13    -0.072913\n",
       "x62    -0.069361\n",
       "x59    -0.064507\n",
       "x72    -0.057125\n",
       "x122   -0.041442\n",
       "x107   -0.026857\n",
       "x19    -0.020853\n",
       "x82    -0.017467\n",
       "x29    -0.010689\n",
       "x12    -0.009049\n",
       "x32    -0.006683\n",
       "x9     -0.006534\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_corr_to_y_asc = df_train_corr_to_y.sort_values(ascending=True)\n",
    "df_train_corr_to_y_asc.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f5d3b10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "strong_negative = ['x57','x41','x60','x44','x105','x67','x119','x61','x13','x62','x59','x72','x122','x107','x19','x82','x29']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef81293",
   "metadata": {},
   "source": [
    "Strong positive correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6046bd58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y       1.000000\n",
       "x17     0.136983\n",
       "x106    0.113577\n",
       "x92     0.085921\n",
       "x91     0.078085\n",
       "x28     0.068710\n",
       "x46     0.067976\n",
       "x118    0.067032\n",
       "x96     0.065964\n",
       "x104    0.061336\n",
       "x117    0.052421\n",
       "x65     0.051633\n",
       "x75     0.043178\n",
       "x45     0.043160\n",
       "x35     0.041194\n",
       "x103    0.039896\n",
       "x39     0.033654\n",
       "x15     0.030245\n",
       "x50     0.012614\n",
       "x71     0.011542\n",
       "x73     0.010830\n",
       "x31     0.010344\n",
       "x64     0.007614\n",
       "x4      0.007267\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_corr_to_y_dsc = df_train_corr_to_y.sort_values(ascending=False)\n",
    "df_train_corr_to_y_dsc.head(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "07a6ba56",
   "metadata": {},
   "outputs": [],
   "source": [
    "strong_positive = ['x17','x106','x92','x91','x28','x46','x118','x96','x104','x117','x65','x75','x45','x35','x103','x39','x15','x50','x71','x73','x31']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdd4830",
   "metadata": {},
   "source": [
    "Later in this notebook, during model building, using only independent variables with strong positive and negative correlation will be included in the experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35375a61",
   "metadata": {},
   "source": [
    "## 3. Modeling\n",
    "The ML algorithm that will be used in this case is XGBoost.\n",
    "\n",
    "<p><strong>XGBoost - Extreme Gradient Boosting</strong></p>\n",
    "XGBoost is the optimized version of Gradient Boosting algorithm through parallel processing (i.e., tree building) and tree pruning using depth-first approach. XGBoost is also able to handle missing values and regularization in order to avoid overfitting/bias. It also has an in-built cross-validation capability.\n",
    "\n",
    "List of experiments:\n",
    "\n",
    "1. Without resampling and with tuning\n",
    "2. SMOTE oversampled (use test set with dropped nan values)\n",
    "3. ADASYN oversampled (use test set with dropped nan values)\n",
    "4. RandomUnderSampler undersampled (use test set with dropped nan values)\n",
    "5. Dropped features with correlation coefficient >-0.01 and <0.01, without resampling\n",
    "\n",
    "Then, to the best model in terms of accuracy, hyperparameter tuning will be performed to find the best combination of parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a696028c",
   "metadata": {},
   "source": [
    "### 3.1. Without resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0db7a1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "16b53fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model is 88.6%\n"
     ]
    }
   ],
   "source": [
    "# fit model no training data\n",
    "xgb_1 = XGBClassifier()\n",
    "xgb_1.fit(X_train, y_train)\n",
    "\n",
    "# Prediction\n",
    "y_pred_1 = xgb_1.predict(X_test)\n",
    "\n",
    "# Evaluation - accuracy\n",
    "accuracy_1 = accuracy_score(y_test,y_pred_1)\n",
    "print(f\"The accuracy of the model is {round(accuracy_1,3)*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b22221",
   "metadata": {},
   "source": [
    "### 3.2. SMOTE oversampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f4101c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model is 88.2%\n"
     ]
    }
   ],
   "source": [
    "xgb_smote = XGBClassifier()\n",
    "xgb_smote.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Prediction\n",
    "y_pred_smote = xgb_smote.predict(X_test_nan_dropped)\n",
    "\n",
    "# Evaluation - accuracy\n",
    "accuracy_smote = accuracy_score(y_test_nan_dropped,y_pred_smote)\n",
    "print(f\"The accuracy of the model is {round(accuracy_smote,3)*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b6e59c",
   "metadata": {},
   "source": [
    "### 3.3. ADASYN oversampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "39383673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model is 88.2%\n"
     ]
    }
   ],
   "source": [
    "xgb_ada = XGBClassifier(random_state=0)\n",
    "xgb_ada.fit(X_train_ada, y_train_ada)\n",
    "\n",
    "# Prediction\n",
    "y_pred_ada = xgb_smote.predict(X_test_nan_dropped)\n",
    "\n",
    "# Evaluation - accuracy\n",
    "accuracy_ada = accuracy_score(y_test_nan_dropped,y_pred_ada)\n",
    "print(f\"The accuracy of the model is {round(accuracy_ada,3)*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd15482",
   "metadata": {},
   "source": [
    "### 3.4. RandomUnderSampler undersampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a7217cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model is 76.0%\n"
     ]
    }
   ],
   "source": [
    "xgb_rus = XGBClassifier(random_state=0)\n",
    "xgb_rus.fit(X_train_rus, y_train_rus)\n",
    "\n",
    "# Prediction\n",
    "y_pred_rus = xgb_rus.predict(X_test_nan_dropped)\n",
    "\n",
    "# Evaluation - accuracy\n",
    "accuracy_rus = accuracy_score(y_test_nan_dropped,y_pred_rus)\n",
    "print(f\"The accuracy of the model is {round(accuracy_rus,3)*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbffa5cc",
   "metadata": {},
   "source": [
    "### 3.5. Dropped features with weak correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f14365ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x57',\n",
       " 'x41',\n",
       " 'x60',\n",
       " 'x44',\n",
       " 'x105',\n",
       " 'x67',\n",
       " 'x119',\n",
       " 'x61',\n",
       " 'x13',\n",
       " 'x62',\n",
       " 'x59',\n",
       " 'x72',\n",
       " 'x122',\n",
       " 'x107',\n",
       " 'x19',\n",
       " 'x82',\n",
       " 'x29']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Attributes with strong negative correlations to y\n",
    "strong_negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0cc0706d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x17',\n",
       " 'x106',\n",
       " 'x92',\n",
       " 'x91',\n",
       " 'x28',\n",
       " 'x46',\n",
       " 'x118',\n",
       " 'x96',\n",
       " 'x104',\n",
       " 'x117',\n",
       " 'x65',\n",
       " 'x75',\n",
       " 'x45',\n",
       " 'x35',\n",
       " 'x103',\n",
       " 'x39',\n",
       " 'x15',\n",
       " 'x50',\n",
       " 'x71',\n",
       " 'x73',\n",
       " 'x31']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Attributes with strong positive correlations to y\n",
    "strong_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "62e52561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x57',\n",
       " 'x41',\n",
       " 'x60',\n",
       " 'x44',\n",
       " 'x105',\n",
       " 'x67',\n",
       " 'x119',\n",
       " 'x61',\n",
       " 'x13',\n",
       " 'x62',\n",
       " 'x59',\n",
       " 'x72',\n",
       " 'x122',\n",
       " 'x107',\n",
       " 'x19',\n",
       " 'x82',\n",
       " 'x29',\n",
       " 'x17',\n",
       " 'x106',\n",
       " 'x92',\n",
       " 'x91',\n",
       " 'x28',\n",
       " 'x46',\n",
       " 'x118',\n",
       " 'x96',\n",
       " 'x104',\n",
       " 'x117',\n",
       " 'x65',\n",
       " 'x75',\n",
       " 'x45',\n",
       " 'x35',\n",
       " 'x103',\n",
       " 'x39',\n",
       " 'x15',\n",
       " 'x50',\n",
       " 'x71',\n",
       " 'x73',\n",
       " 'x31',\n",
       " 'y']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strong_correlations = strong_negative+strong_positive\n",
    "strong_correlations.append('y')\n",
    "strong_correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b48de36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy dataset with only the above attributes\n",
    "df_train_sc = df_train[:]\n",
    "df_train_sc = df_train_sc[strong_correlations]\n",
    "df_test_sc = df_test[:]\n",
    "df_test_sc = df_test_sc[strong_correlations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "dbfcc106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x57</th>\n",
       "      <th>x41</th>\n",
       "      <th>x60</th>\n",
       "      <th>x44</th>\n",
       "      <th>x105</th>\n",
       "      <th>x67</th>\n",
       "      <th>x119</th>\n",
       "      <th>x61</th>\n",
       "      <th>x13</th>\n",
       "      <th>x62</th>\n",
       "      <th>...</th>\n",
       "      <th>x45</th>\n",
       "      <th>x35</th>\n",
       "      <th>x103</th>\n",
       "      <th>x39</th>\n",
       "      <th>x15</th>\n",
       "      <th>x50</th>\n",
       "      <th>x71</th>\n",
       "      <th>x73</th>\n",
       "      <th>x31</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.395665</td>\n",
       "      <td>21.860965</td>\n",
       "      <td>-23.431641</td>\n",
       "      <td>16.179453</td>\n",
       "      <td>36.329967</td>\n",
       "      <td>-58.953416</td>\n",
       "      <td>0.773809</td>\n",
       "      <td>13.751744</td>\n",
       "      <td>-8.340786</td>\n",
       "      <td>-26.500714</td>\n",
       "      <td>...</td>\n",
       "      <td>39.545280</td>\n",
       "      <td>11.068075</td>\n",
       "      <td>0.514885</td>\n",
       "      <td>-7.450657</td>\n",
       "      <td>-19.878081</td>\n",
       "      <td>-55.922397</td>\n",
       "      <td>19.563718</td>\n",
       "      <td>32.209681</td>\n",
       "      <td>-27.698764</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.362896</td>\n",
       "      <td>18.327611</td>\n",
       "      <td>1.183948</td>\n",
       "      <td>-34.864322</td>\n",
       "      <td>-13.448378</td>\n",
       "      <td>74.633579</td>\n",
       "      <td>7.065852</td>\n",
       "      <td>-9.282450</td>\n",
       "      <td>-5.618335</td>\n",
       "      <td>19.474037</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.474592</td>\n",
       "      <td>-13.186784</td>\n",
       "      <td>-1.845015</td>\n",
       "      <td>-0.962187</td>\n",
       "      <td>3.481345</td>\n",
       "      <td>46.166641</td>\n",
       "      <td>-10.319307</td>\n",
       "      <td>21.524979</td>\n",
       "      <td>7.889010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.473236</td>\n",
       "      <td>6.898550</td>\n",
       "      <td>-2.325219</td>\n",
       "      <td>24.095527</td>\n",
       "      <td>-25.670791</td>\n",
       "      <td>52.444828</td>\n",
       "      <td>-8.598553</td>\n",
       "      <td>-7.472724</td>\n",
       "      <td>-3.618850</td>\n",
       "      <td>19.527319</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.703214</td>\n",
       "      <td>-10.201114</td>\n",
       "      <td>-0.850936</td>\n",
       "      <td>-17.172271</td>\n",
       "      <td>3.771034</td>\n",
       "      <td>27.729470</td>\n",
       "      <td>-14.488131</td>\n",
       "      <td>-6.662494</td>\n",
       "      <td>11.004250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.478409</td>\n",
       "      <td>14.613527</td>\n",
       "      <td>6.255019</td>\n",
       "      <td>-50.442312</td>\n",
       "      <td>4.057570</td>\n",
       "      <td>7.447102</td>\n",
       "      <td>8.194975</td>\n",
       "      <td>12.480775</td>\n",
       "      <td>-2.399277</td>\n",
       "      <td>-25.743925</td>\n",
       "      <td>...</td>\n",
       "      <td>11.822118</td>\n",
       "      <td>3.699499</td>\n",
       "      <td>-1.124832</td>\n",
       "      <td>7.610184</td>\n",
       "      <td>-0.142621</td>\n",
       "      <td>-1.268939</td>\n",
       "      <td>37.358118</td>\n",
       "      <td>58.099294</td>\n",
       "      <td>-33.151758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.247766</td>\n",
       "      <td>-16.016833</td>\n",
       "      <td>1.628471</td>\n",
       "      <td>47.675250</td>\n",
       "      <td>45.817767</td>\n",
       "      <td>-26.552274</td>\n",
       "      <td>2.330789</td>\n",
       "      <td>11.202072</td>\n",
       "      <td>-1.973822</td>\n",
       "      <td>-2.409916</td>\n",
       "      <td>...</td>\n",
       "      <td>4.629616</td>\n",
       "      <td>8.813286</td>\n",
       "      <td>-0.404615</td>\n",
       "      <td>5.343754</td>\n",
       "      <td>-1.235130</td>\n",
       "      <td>14.594703</td>\n",
       "      <td>23.074105</td>\n",
       "      <td>47.049903</td>\n",
       "      <td>-12.489286</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        x57        x41        x60        x44       x105        x67      x119  \\\n",
       "0 -0.395665  21.860965 -23.431641  16.179453  36.329967 -58.953416  0.773809   \n",
       "1 -0.362896  18.327611   1.183948 -34.864322 -13.448378  74.633579  7.065852   \n",
       "2 -1.473236   6.898550  -2.325219  24.095527 -25.670791  52.444828 -8.598553   \n",
       "3  5.478409  14.613527   6.255019 -50.442312   4.057570   7.447102  8.194975   \n",
       "4  5.247766 -16.016833   1.628471  47.675250  45.817767 -26.552274  2.330789   \n",
       "\n",
       "         x61       x13        x62  ...        x45        x35      x103  \\\n",
       "0  13.751744 -8.340786 -26.500714  ...  39.545280  11.068075  0.514885   \n",
       "1  -9.282450 -5.618335  19.474037  ...  -4.474592 -13.186784 -1.845015   \n",
       "2  -7.472724 -3.618850  19.527319  ...  -6.703214 -10.201114 -0.850936   \n",
       "3  12.480775 -2.399277 -25.743925  ...  11.822118   3.699499 -1.124832   \n",
       "4  11.202072 -1.973822  -2.409916  ...   4.629616   8.813286 -0.404615   \n",
       "\n",
       "         x39        x15        x50        x71        x73        x31  y  \n",
       "0  -7.450657 -19.878081 -55.922397  19.563718  32.209681 -27.698764  0  \n",
       "1  -0.962187   3.481345  46.166641 -10.319307  21.524979   7.889010  0  \n",
       "2 -17.172271   3.771034  27.729470 -14.488131  -6.662494  11.004250  0  \n",
       "3   7.610184  -0.142621  -1.268939  37.358118  58.099294 -33.151758  0  \n",
       "4   5.343754  -1.235130  14.594703  23.074105  47.049903 -12.489286  1  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_sc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7c50dbad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x57</th>\n",
       "      <th>x41</th>\n",
       "      <th>x60</th>\n",
       "      <th>x44</th>\n",
       "      <th>x105</th>\n",
       "      <th>x67</th>\n",
       "      <th>x119</th>\n",
       "      <th>x61</th>\n",
       "      <th>x13</th>\n",
       "      <th>x62</th>\n",
       "      <th>...</th>\n",
       "      <th>x45</th>\n",
       "      <th>x35</th>\n",
       "      <th>x103</th>\n",
       "      <th>x39</th>\n",
       "      <th>x15</th>\n",
       "      <th>x50</th>\n",
       "      <th>x71</th>\n",
       "      <th>x73</th>\n",
       "      <th>x31</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.259909</td>\n",
       "      <td>13.055414</td>\n",
       "      <td>-14.315786</td>\n",
       "      <td>-38.643101</td>\n",
       "      <td>25.630266</td>\n",
       "      <td>58.568901</td>\n",
       "      <td>-9.897690</td>\n",
       "      <td>-14.132548</td>\n",
       "      <td>4.959509</td>\n",
       "      <td>48.656974</td>\n",
       "      <td>...</td>\n",
       "      <td>-51.054889</td>\n",
       "      <td>0.044943</td>\n",
       "      <td>-4.374817</td>\n",
       "      <td>16.140605</td>\n",
       "      <td>-2.030356</td>\n",
       "      <td>70.957171</td>\n",
       "      <td>6.621634</td>\n",
       "      <td>4.653935</td>\n",
       "      <td>44.933636</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4.918258</td>\n",
       "      <td>-3.085948</td>\n",
       "      <td>0.160628</td>\n",
       "      <td>-12.443104</td>\n",
       "      <td>42.942199</td>\n",
       "      <td>-7.136370</td>\n",
       "      <td>7.781887</td>\n",
       "      <td>-0.786236</td>\n",
       "      <td>-2.020895</td>\n",
       "      <td>12.591929</td>\n",
       "      <td>...</td>\n",
       "      <td>22.933258</td>\n",
       "      <td>-1.752173</td>\n",
       "      <td>0.252021</td>\n",
       "      <td>9.891922</td>\n",
       "      <td>-9.165506</td>\n",
       "      <td>-6.377254</td>\n",
       "      <td>-23.748115</td>\n",
       "      <td>-0.305002</td>\n",
       "      <td>24.533511</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.480739</td>\n",
       "      <td>-5.210111</td>\n",
       "      <td>20.649833</td>\n",
       "      <td>31.204872</td>\n",
       "      <td>-1.026669</td>\n",
       "      <td>38.793240</td>\n",
       "      <td>6.815214</td>\n",
       "      <td>-1.297034</td>\n",
       "      <td>6.498108</td>\n",
       "      <td>4.741591</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.547329</td>\n",
       "      <td>-0.216140</td>\n",
       "      <td>-2.128526</td>\n",
       "      <td>-20.987141</td>\n",
       "      <td>9.434490</td>\n",
       "      <td>2.802802</td>\n",
       "      <td>-24.668008</td>\n",
       "      <td>21.679257</td>\n",
       "      <td>-7.476300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.065273</td>\n",
       "      <td>60.515760</td>\n",
       "      <td>55.892023</td>\n",
       "      <td>-2.648475</td>\n",
       "      <td>85.185923</td>\n",
       "      <td>40.321194</td>\n",
       "      <td>3.158137</td>\n",
       "      <td>31.886691</td>\n",
       "      <td>12.038212</td>\n",
       "      <td>17.060105</td>\n",
       "      <td>...</td>\n",
       "      <td>22.486305</td>\n",
       "      <td>3.462986</td>\n",
       "      <td>3.969886</td>\n",
       "      <td>-9.520847</td>\n",
       "      <td>-12.081526</td>\n",
       "      <td>-1.136188</td>\n",
       "      <td>-21.293066</td>\n",
       "      <td>14.382409</td>\n",
       "      <td>26.038436</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.221712</td>\n",
       "      <td>-49.429186</td>\n",
       "      <td>-23.720409</td>\n",
       "      <td>35.199209</td>\n",
       "      <td>-2.742862</td>\n",
       "      <td>-52.903473</td>\n",
       "      <td>-3.867657</td>\n",
       "      <td>5.032388</td>\n",
       "      <td>5.525227</td>\n",
       "      <td>-8.704657</td>\n",
       "      <td>...</td>\n",
       "      <td>-38.270309</td>\n",
       "      <td>13.566662</td>\n",
       "      <td>2.115363</td>\n",
       "      <td>20.445398</td>\n",
       "      <td>-0.723274</td>\n",
       "      <td>64.575428</td>\n",
       "      <td>54.881302</td>\n",
       "      <td>2.176974</td>\n",
       "      <td>1.656484</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.573296</td>\n",
       "      <td>-54.207520</td>\n",
       "      <td>-13.298627</td>\n",
       "      <td>61.153183</td>\n",
       "      <td>40.806962</td>\n",
       "      <td>-16.649762</td>\n",
       "      <td>2.512500</td>\n",
       "      <td>-8.352572</td>\n",
       "      <td>4.375033</td>\n",
       "      <td>56.577148</td>\n",
       "      <td>...</td>\n",
       "      <td>-38.722231</td>\n",
       "      <td>8.095999</td>\n",
       "      <td>-2.589531</td>\n",
       "      <td>19.825293</td>\n",
       "      <td>2.514180</td>\n",
       "      <td>96.374311</td>\n",
       "      <td>-52.646575</td>\n",
       "      <td>-19.855371</td>\n",
       "      <td>37.152902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.264067</td>\n",
       "      <td>-31.415760</td>\n",
       "      <td>-14.204266</td>\n",
       "      <td>-38.582393</td>\n",
       "      <td>2.053739</td>\n",
       "      <td>0.839982</td>\n",
       "      <td>-6.453662</td>\n",
       "      <td>-11.628646</td>\n",
       "      <td>-2.122468</td>\n",
       "      <td>-23.850243</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.885580</td>\n",
       "      <td>7.759992</td>\n",
       "      <td>2.211927</td>\n",
       "      <td>0.417666</td>\n",
       "      <td>2.695669</td>\n",
       "      <td>24.008443</td>\n",
       "      <td>63.401788</td>\n",
       "      <td>55.775852</td>\n",
       "      <td>20.444293</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-6.163186</td>\n",
       "      <td>9.041720</td>\n",
       "      <td>-12.258371</td>\n",
       "      <td>-37.583716</td>\n",
       "      <td>-58.085827</td>\n",
       "      <td>47.075475</td>\n",
       "      <td>6.235511</td>\n",
       "      <td>-10.868620</td>\n",
       "      <td>-8.394505</td>\n",
       "      <td>33.790714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.943897</td>\n",
       "      <td>-17.215546</td>\n",
       "      <td>-2.334406</td>\n",
       "      <td>6.531753</td>\n",
       "      <td>3.381380</td>\n",
       "      <td>82.600231</td>\n",
       "      <td>-44.264648</td>\n",
       "      <td>-45.984839</td>\n",
       "      <td>-1.072960</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-4.166338</td>\n",
       "      <td>-36.640211</td>\n",
       "      <td>1.752627</td>\n",
       "      <td>-25.495612</td>\n",
       "      <td>-21.559009</td>\n",
       "      <td>-55.832402</td>\n",
       "      <td>-2.424945</td>\n",
       "      <td>10.755499</td>\n",
       "      <td>1.507899</td>\n",
       "      <td>-23.464339</td>\n",
       "      <td>...</td>\n",
       "      <td>35.364796</td>\n",
       "      <td>3.089724</td>\n",
       "      <td>-0.898622</td>\n",
       "      <td>21.964271</td>\n",
       "      <td>4.042090</td>\n",
       "      <td>-28.975374</td>\n",
       "      <td>4.951003</td>\n",
       "      <td>11.122772</td>\n",
       "      <td>-27.483886</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.277016</td>\n",
       "      <td>38.108368</td>\n",
       "      <td>8.625983</td>\n",
       "      <td>25.744151</td>\n",
       "      <td>22.272007</td>\n",
       "      <td>40.094550</td>\n",
       "      <td>14.437596</td>\n",
       "      <td>-14.814127</td>\n",
       "      <td>2.851070</td>\n",
       "      <td>33.685441</td>\n",
       "      <td>...</td>\n",
       "      <td>-60.450034</td>\n",
       "      <td>-11.217944</td>\n",
       "      <td>-1.993447</td>\n",
       "      <td>11.398218</td>\n",
       "      <td>4.412487</td>\n",
       "      <td>2.972844</td>\n",
       "      <td>-3.222132</td>\n",
       "      <td>-60.719663</td>\n",
       "      <td>15.600088</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         x57        x41        x60        x44       x105        x67  \\\n",
       "0   0.259909  13.055414 -14.315786 -38.643101  25.630266  58.568901   \n",
       "1  -4.918258  -3.085948   0.160628 -12.443104  42.942199  -7.136370   \n",
       "2   4.480739  -5.210111  20.649833  31.204872  -1.026669  38.793240   \n",
       "3  10.065273  60.515760  55.892023  -2.648475  85.185923  40.321194   \n",
       "4   2.221712 -49.429186 -23.720409  35.199209  -2.742862 -52.903473   \n",
       "5  -1.573296 -54.207520 -13.298627  61.153183  40.806962 -16.649762   \n",
       "6   1.264067 -31.415760 -14.204266 -38.582393   2.053739   0.839982   \n",
       "7  -6.163186   9.041720 -12.258371 -37.583716 -58.085827  47.075475   \n",
       "8  -4.166338 -36.640211   1.752627 -25.495612 -21.559009 -55.832402   \n",
       "9   3.277016  38.108368   8.625983  25.744151  22.272007  40.094550   \n",
       "\n",
       "        x119        x61        x13        x62  ...        x45        x35  \\\n",
       "0  -9.897690 -14.132548   4.959509  48.656974  ... -51.054889   0.044943   \n",
       "1   7.781887  -0.786236  -2.020895  12.591929  ...  22.933258  -1.752173   \n",
       "2   6.815214  -1.297034   6.498108   4.741591  ...  -8.547329  -0.216140   \n",
       "3   3.158137  31.886691  12.038212  17.060105  ...  22.486305   3.462986   \n",
       "4  -3.867657   5.032388   5.525227  -8.704657  ... -38.270309  13.566662   \n",
       "5   2.512500  -8.352572   4.375033  56.577148  ... -38.722231   8.095999   \n",
       "6  -6.453662 -11.628646  -2.122468 -23.850243  ... -14.885580   7.759992   \n",
       "7   6.235511 -10.868620  -8.394505  33.790714  ...   0.943897 -17.215546   \n",
       "8  -2.424945  10.755499   1.507899 -23.464339  ...  35.364796   3.089724   \n",
       "9  14.437596 -14.814127   2.851070  33.685441  ... -60.450034 -11.217944   \n",
       "\n",
       "       x103        x39        x15        x50        x71        x73        x31  \\\n",
       "0 -4.374817  16.140605  -2.030356  70.957171   6.621634   4.653935  44.933636   \n",
       "1  0.252021   9.891922  -9.165506  -6.377254 -23.748115  -0.305002  24.533511   \n",
       "2 -2.128526 -20.987141   9.434490   2.802802 -24.668008  21.679257  -7.476300   \n",
       "3  3.969886  -9.520847 -12.081526  -1.136188 -21.293066  14.382409  26.038436   \n",
       "4  2.115363  20.445398  -0.723274  64.575428  54.881302   2.176974   1.656484   \n",
       "5 -2.589531  19.825293   2.514180  96.374311 -52.646575 -19.855371  37.152902   \n",
       "6  2.211927   0.417666   2.695669  24.008443  63.401788  55.775852  20.444293   \n",
       "7 -2.334406   6.531753   3.381380  82.600231 -44.264648 -45.984839  -1.072960   \n",
       "8 -0.898622  21.964271   4.042090 -28.975374   4.951003  11.122772 -27.483886   \n",
       "9 -1.993447  11.398218   4.412487   2.972844  -3.222132 -60.719663  15.600088   \n",
       "\n",
       "   y  \n",
       "0  0  \n",
       "1  0  \n",
       "2  0  \n",
       "3  0  \n",
       "4  0  \n",
       "5  1  \n",
       "6  1  \n",
       "7  0  \n",
       "8  1  \n",
       "9  0  \n",
       "\n",
       "[10 rows x 39 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_sc.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8ab2a150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the resulted dataset to X and y\n",
    "sc_features = strong_negative + strong_positive\n",
    "X_train_sc = df_train_sc[sc_features].values\n",
    "y_train_sc = df_train_sc['y'].values.flatten()\n",
    "X_test_sc = df_test_sc[sc_features].values\n",
    "y_test_sc = df_test_sc['y'].values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ee15f7b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model is 88.8%\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "xgb_sc = XGBClassifier(random_state=0)\n",
    "xgb_sc.fit(X_train_sc, y_train_sc)\n",
    "\n",
    "# Prediction\n",
    "y_pred_sc = xgb_sc.predict(X_test_sc)\n",
    "\n",
    "# Evaluation - accuracy\n",
    "accuracy_sc = accuracy_score(y_test_sc,y_pred_sc)\n",
    "print(f\"The accuracy of the model is {round(accuracy_sc,3)*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2c857a",
   "metadata": {},
   "source": [
    "### 3.6. Dropped features with weak correlation to y and with hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e9eda4",
   "metadata": {},
   "source": [
    "#### 3.6.1 Intuitively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "dfe6c288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model is 88.6%\n"
     ]
    }
   ],
   "source": [
    "xgb_sc_tuned_1 = XGBClassifier(random_state=0,max_depth=5,n_estimators=100,learning_rate=0.3,subsample=0.6,gamma=0.8,reg_lambda=1.2,alpha=0.2)\n",
    "xgb_sc_tuned_1.fit(X_train_sc, y_train_sc)\n",
    "\n",
    "# Prediction\n",
    "y_pred_sc_tuned_1 = xgb_sc_tuned_1.predict(X_test_sc)\n",
    "\n",
    "# Evaluation - accuracy\n",
    "accuracy_sc_tuned_1 = accuracy_score(y_test_sc,y_pred_sc_tuned_1)\n",
    "print(f\"The accuracy of the model is {round(accuracy_sc_tuned_1,3)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "7eff8707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model is 88.8%\n"
     ]
    }
   ],
   "source": [
    "xgb_sc_tuned_2 = XGBClassifier(random_state=0,max_depth=5,n_estimators=500,learning_rate=0.3,subsample=0.6,gamma=0.8,reg_lambda=1.2,alpha=0.2)\n",
    "xgb_sc_tuned_2.fit(X_train_sc, y_train_sc)\n",
    "\n",
    "# Prediction\n",
    "y_pred_sc_tuned_2 = xgb_sc_tuned_2.predict(X_test_sc)\n",
    "\n",
    "# Evaluation - accuracy\n",
    "accuracy_sc_tuned_2 = accuracy_score(y_test_sc,y_pred_sc_tuned_2)\n",
    "print(f\"The accuracy of the model is {round(accuracy_sc_tuned_2,3)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "0ee7a355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class=0, n=20696 (82.784%)\n",
      "Class=1, n=4304 (17.216%)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAWaElEQVR4nO3df7DddX3n8edrQ6GuliXIbTYm1AQ3toNMGySDjFVXi0LAHYO7HRtmK9GyRlbYqWNntqH8gYPLLNpad5h1caJmCbsKUtEhq7gYo1unY4NcNAJBMZdfQ7IhuSVU2rVDi33vH+dzu18u98fhnnvPTZbnY+bM+Z739/P9nvf5csnrfn+c+01VIUl6cftHi92AJGnxGQaSJMNAkmQYSJIwDCRJwHGL3cBcnXLKKbVq1arFbkOSjin33HPPX1TVyOT6MRsGq1atYnR0dLHbkKRjSpLHpqp7mEiSZBhIkgwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRzD30AexKotX13sFnSUevS6ty92C9KicM9AkmQYSJIMA0kSfYRBklOTfCvJA0n2JvndVj85yc4k+9rz0lZPkuuTjCW5N8lrO+va1MbvS7KpUz8ryX1tmeuTZCE+rCRpav3sGTwL/F5VnQ6cA1ye5HRgC7CrqtYAu9prgAuANe2xGbgBeuEBXA28DjgbuHoiQNqY93WWWz/4R5Mk9WvWMKiqg1X1vTb9V8APgRXABmB7G7YduKhNbwBuqp7dwElJlgPnAzur6khVPQXsBNa3eSdW1e6qKuCmzrokSUPwgs4ZJFkFnAncBSyrqoNt1hPAsja9Ani8s9j+Vpupvn+K+lTvvznJaJLR8fHxF9K6JGkGfYdBkpcBtwEfrKqnu/Pab/Q1z709T1Vtrap1VbVuZOR5d22TJM1RX2GQ5OfoBcHnqupLrXyoHeKhPR9u9QPAqZ3FV7baTPWVU9QlSUPSz9VEAT4L/LCq/rgzawcwcUXQJuD2Tv2SdlXROcBP2uGkO4HzkixtJ47PA+5s855Ock57r0s665IkDUE/f47i14F3A/cl2dNqfwBcB9ya5FLgMeBdbd4dwIXAGPBT4L0AVXUkyUeAu9u4a6rqSJv+AHAj8BLga+0hSRqSWcOgqv4MmO66/3OnGF/A5dOsaxuwbYr6KHDGbL1IkhaG30CWJBkGkiTDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiT6u+3ltiSHk9zfqX0hyZ72eHTiDmhJViX5m868T3WWOSvJfUnGklzfbnFJkpOT7Eyyrz0vXYDPKUmaQT97BjcC67uFqvqtqlpbVWuB24AvdWY/NDGvqi7r1G8A3gesaY+JdW4BdlXVGmBXey1JGqJZw6Cqvg0cmWpe++3+XcDNM60jyXLgxKra3W6LeRNwUZu9Adjeprd36pKkIRn0nMEbgUNVta9TW53k+0n+NMkbW20FsL8zZn+rASyrqoNt+glg2XRvlmRzktEko+Pj4wO2LkmaMGgYXMxz9woOAr9UVWcCHwI+n+TEflfW9hpqhvlbq2pdVa0bGRmZa8+SpEmOm+uCSY4D/iVw1kStqp4BnmnT9yR5CHg1cABY2Vl8ZasBHEqyvKoOtsNJh+fakyRpbgbZM3gr8KOq+ofDP0lGkixp06fRO1H8cDsM9HSSc9p5hkuA29tiO4BNbXpTpy5JGpJ+Li29Gfhz4JeT7E9yaZu1keefOH4TcG+71PSLwGVVNXHy+QPAZ4Ax4CHga61+HfC2JPvoBcx1c/84kqS5mPUwUVVdPE39PVPUbqN3qelU40eBM6aoPwmcO1sfkqSF4zeQJUmGgSTJMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSSJ/u50ti3J4ST3d2ofTnIgyZ72uLAz78okY0keTHJ+p76+1caSbOnUVye5q9W/kOT4+fyAkqTZ9bNncCOwfor6J6pqbXvcAZDkdHq3w3xNW+a/JFnS7ov8SeAC4HTg4jYW4KNtXf8MeAq4dPIbSZIW1qxhUFXfBo7MNq7ZANxSVc9U1SP07nd8dnuMVdXDVfW3wC3AhiQBfoPe/ZIBtgMXvbCPIEka1CDnDK5Icm87jLS01VYAj3fG7G+16eovB/6yqp6dVJ9Sks1JRpOMjo+PD9C6JKlrrmFwA/AqYC1wEPj4fDU0k6raWlXrqmrdyMjIMN5Skl4UjpvLQlV1aGI6yaeBr7SXB4BTO0NXthrT1J8ETkpyXNs76I6XJA3JnPYMkizvvHwnMHGl0Q5gY5ITkqwG1gDfBe4G1rQrh46nd5J5R1UV8C3gN9vym4Db59KTJGnuZt0zSHIz8GbglCT7gauBNydZCxTwKPB+gKram+RW4AHgWeDyqvpZW88VwJ3AEmBbVe1tb/H7wC1J/gPwfeCz8/XhJEn9mTUMquriKcrT/oNdVdcC105RvwO4Y4r6w/SuNpIkLRK/gSxJMgwkSYaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSfQRBkm2JTmc5P5O7Q+T/CjJvUm+nOSkVl+V5G+S7GmPT3WWOSvJfUnGklyfJK1+cpKdSfa156UL8DklSTPoZ8/gRmD9pNpO4Iyq+lXgx8CVnXkPVdXa9risU78BeB+9+yKv6axzC7CrqtYAu9prSdIQzRoGVfVt4Mik2ter6tn2cjewcqZ1JFkOnFhVu6uqgJuAi9rsDcD2Nr29U5ckDcl8nDP4HeBrnderk3w/yZ8meWOrrQD2d8bsbzWAZVV1sE0/ASyb7o2SbE4ymmR0fHx8HlqXJMGAYZDkKuBZ4HOtdBD4pao6E/gQ8PkkJ/a7vrbXUDPM31pV66pq3cjIyACdS5K6jpvrgkneA/wL4Nz2jzhV9QzwTJu+J8lDwKuBAzz3UNLKVgM4lGR5VR1sh5MOz7UnSdLczGnPIMl64N8D76iqn3bqI0mWtOnT6J0ofrgdBno6yTntKqJLgNvbYjuATW16U6cuSRqSWfcMktwMvBk4Jcl+4Gp6Vw+dAOxsV4jublcOvQm4JsnfAX8PXFZVEyefP0DvyqSX0DvHMHGe4Trg1iSXAo8B75qXTyZJ6tusYVBVF09R/uw0Y28Dbptm3ihwxhT1J4FzZ+tDkrRw/AayJMkwkCQZBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCTRZxgk2ZbkcJL7O7WTk+xMsq89L231JLk+yViSe5O8trPMpjZ+X5JNnfpZSe5ry1zfbo0pSRqSfvcMbgTWT6ptAXZV1RpgV3sNcAG9ex+vATYDN0AvPOjdMvN1wNnA1RMB0sa8r7Pc5PeSJC2gvsKgqr4NHJlU3gBsb9PbgYs69ZuqZzdwUpLlwPnAzqo6UlVPATuB9W3eiVW1u6oKuKmzLknSEAxyzmBZVR1s008Ay9r0CuDxzrj9rTZTff8U9edJsjnJaJLR8fHxAVqXJHXNywnk9ht9zce6ZnmfrVW1rqrWjYyMLPTbSdKLxiBhcKgd4qE9H271A8CpnXErW22m+sop6pKkIRkkDHYAE1cEbQJu79QvaVcVnQP8pB1OuhM4L8nSduL4PODONu/pJOe0q4gu6axLkjQEx/UzKMnNwJuBU5Lsp3dV0HXArUkuBR4D3tWG3wFcCIwBPwXeC1BVR5J8BLi7jbumqiZOSn+A3hVLLwG+1h6SpCHpKwyq6uJpZp07xdgCLp9mPduAbVPUR4Ez+ulFkjT//AayJMkwkCQZBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCQxQBgk+eUkezqPp5N8MMmHkxzo1C/sLHNlkrEkDyY5v1Nf32pjSbYM+qEkSS9MX3c6m0pVPQisBUiyhN5N7L9M7zaXn6iqP+qOT3I6sBF4DfAK4BtJXt1mfxJ4G7AfuDvJjqp6YK69SZJemDmHwSTnAg9V1WO9e9pPaQNwS1U9AzySZAw4u80bq6qHAZLc0sYaBpI0JPN1zmAjcHPn9RVJ7k2yLcnSVlsBPN4Zs7/Vpqs/T5LNSUaTjI6Pj89T65KkgcMgyfHAO4A/aaUbgFfRO4R0EPj4oO8xoaq2VtW6qlo3MjIyX6uVpBe9+ThMdAHwvao6BDDxDJDk08BX2ssDwKmd5Va2GjPUJUlDMB+HiS6mc4goyfLOvHcC97fpHcDGJCckWQ2sAb4L3A2sSbK67WVsbGMlSUMy0J5BkpfSuwro/Z3yx5KsBQp4dGJeVe1Nciu9E8PPApdX1c/aeq4A7gSWANuqau8gfUmSXpiBwqCq/g/w8km1d88w/lrg2inqdwB3DNKLJGnu/AayJMkwkCQZBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCQxD2GQ5NEk9yXZk2S01U5OsjPJvva8tNWT5PokY0nuTfLazno2tfH7kmwatC9JUv/ma8/gLVW1tqrWtddbgF1VtQbY1V4DXEDv3sdrgM3ADdALD+Bq4HXA2cDVEwEiSVp4C3WYaAOwvU1vBy7q1G+qnt3ASUmWA+cDO6vqSFU9BewE1i9Qb5KkSeYjDAr4epJ7kmxutWVVdbBNPwEsa9MrgMc7y+5vtenqz5Fkc5LRJKPj4+Pz0LokCeC4eVjHG6rqQJJfBHYm+VF3ZlVVkpqH96GqtgJbAdatWzcv65QkzcOeQVUdaM+HgS/TO+Z/qB3+oT0fbsMPAKd2Fl/ZatPVJUlDMFAYJHlpkl+YmAbOA+4HdgATVwRtAm5v0zuAS9pVRecAP2mHk+4EzkuytJ04Pq/VJElDMOhhomXAl5NMrOvzVfU/k9wN3JrkUuAx4F1t/B3AhcAY8FPgvQBVdSTJR4C727hrqurIgL1Jkvo0UBhU1cPAr01RfxI4d4p6AZdPs65twLZB+pEkzY3fQJYkzcvVRJLm2aotX13sFnSUevS6ty/Iet0zkCQZBpIkw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkhggDJKcmuRbSR5IsjfJ77b6h5McSLKnPS7sLHNlkrEkDyY5v1Nf32pjSbYM9pEkSS/UIPczeBb4var6XrsP8j1JdrZ5n6iqP+oOTnI6sBF4DfAK4BtJXt1mfxJ4G7AfuDvJjqp6YIDeJEkvwJzDoN3I/mCb/qskPwRWzLDIBuCWqnoGeCTJGHB2mzfWbqFJklvaWMNAkoZkXs4ZJFkFnAnc1UpXJLk3ybYkS1ttBfB4Z7H9rTZdfar32ZxkNMno+Pj4fLQuSWIewiDJy4DbgA9W1dPADcCrgLX09hw+Puh7TKiqrVW1rqrWjYyMzNdqJelFb6B7ICf5OXpB8Lmq+hJAVR3qzP808JX28gBwamfxla3GDHVJ0hAMcjVRgM8CP6yqP+7Ul3eGvRO4v03vADYmOSHJamAN8F3gbmBNktVJjqd3knnHXPuSJL1wg+wZ/DrwbuC+JHta7Q+Ai5OsBQp4FHg/QFXtTXIrvRPDzwKXV9XPAJJcAdwJLAG2VdXeAfqSJL1Ag1xN9GdApph1xwzLXAtcO0X9jpmWkyQtLL+BLEkyDCRJhoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJHEVhkGR9kgeTjCXZstj9SNKLyVERBkmWAJ8ELgBOp3frzNMXtytJevE4KsIAOBsYq6qHq+pvgVuADYvckyS9aMz5HsjzbAXweOf1fuB1kwcl2Qxsbi//OsmDQ+htrk4B/mKxm+jTsdLrgveZj87Latye8+9Y6fVY+Bl95VTFoyUM+lJVW4Gti91HP5KMVtW6xe6jH8dKr/Y5v46VPuHY6fVY6XMqR8thogPAqZ3XK1tNkjQER0sY3A2sSbI6yfHARmDHIvckSS8aR8Vhoqp6NskVwJ3AEmBbVe1d5LYGdUwczmqOlV7tc34dK33CsdPrsdLn86SqFrsHSdIiO1oOE0mSFpFhIEkyDAaR5OQkO5Psa89LpxizNsmfJ9mb5N4kv9WZd2OSR5LsaY+189zfjH/iI8kJSb7Q5t+VZFVn3pWt/mCS8+ezrzn0+aEkD7TttyvJKzvzftbZfgt+0UEfvb4nyXinp3/Tmbep/azsS7Jpkfv8RKfHHyf5y868oW3TJNuSHE5y/zTzk+T69jnuTfLazrxhbs/Z+vzXrb/7knwnya915j3a6nuSjC5knwOpKh9zfAAfA7a06S3AR6cY82pgTZt+BXAQOKm9vhH4zQXqbQnwEHAacDzwA+D0SWM+AHyqTW8EvtCmT2/jTwBWt/UsWcQ+3wL84zb9byf6bK//eoj/vfvp9T3Af55i2ZOBh9vz0ja9dLH6nDT+39G7aGMxtumbgNcC908z/0Lga0CAc4C7hr09++zz9RPvT+/P6tzVmfcocMqwtulcH+4ZDGYDsL1Nbwcumjygqn5cVfva9P8GDgMjQ+itnz/x0e3/i8C5SdLqt1TVM1X1CDDW1rcofVbVt6rqp+3lbnrfQ1kMg/zZlPOBnVV1pKqeAnYC64+SPi8Gbl6gXmZUVd8GjswwZANwU/XsBk5Kspzhbs9Z+6yq77Q+YHF/RufMMBjMsqo62KafAJbNNDjJ2fR+U3uoU7627V5+IskJ89jbVH/iY8V0Y6rqWeAnwMv7XHaYfXZdSu83xQk/n2Q0ye4kFy1Af1399vqv2n/TLyaZ+DLlUblN2yG31cA3O+VhbtPZTPdZhrk9X6jJP6MFfD3JPe1P6hyVjorvGRzNknwD+KdTzLqq+6KqKsm01+m232b+G7Cpqv6+la+kFyLH07s++feBa+aj7/8fJfltYB3wzzvlV1bVgSSnAd9Mcl9VPTT1GobifwA3V9UzSd5Pb8/rNxaxn9lsBL5YVT/r1I62bXrMSPIWemHwhk75DW17/iKwM8mP2p7GUcU9g1lU1Vur6owpHrcDh9o/8hP/2B+eah1JTgS+ClzVdnUn1n2w7f4+A/xX5vdQTD9/4uMfxiQ5DvgnwJN9LjvMPknyVnoB/I62vQCoqgPt+WHgfwFnLlCfffVaVU92+vsMcFa/yw6zz46NTDpENORtOpvpPstR9ydskvwqvf/mG6rqyYl6Z3seBr7Mwh1yHcxin7Q4lh/AH/LcE8gfm2LM8cAu4INTzFvengP8J+C6eeztOHon1Vbz/04ivmbSmMt57gnkW9v0a3juCeSHWbgTyP30eSa9Q2trJtWXAie06VOAfcxwonRIvS7vTL8T2N2mTwYeaT0vbdMnL1afbdyv0Du5mcXapu19VjH9idm389wTyN8d9vbss89fondu7fWT6i8FfqEz/R1g/UL2OefPt9gNHMsPesfXd7X/Yb4x8cNI71DGZ9r0bwN/B+zpPNa2ed8E7gPuB/478LJ57u9C4MftH9KrWu0aer9dA/w88Cfth/i7wGmdZa9qyz0IXLDA23G2Pr8BHOpsvx2t/vq2/X7Qni8dwn/z2Xr9j8De1tO3gF/pLPs7bVuPAe9dzD7b6w8z6ReQYW9TenslB9v/I/vpHWK5DLiszQ+9G1891PpZt0jbc7Y+PwM81fkZHW3109q2/EH7ubhqoX9G5/rwz1FIkjxnIEkyDCRJGAaSJAwDSRKGgSQJw0CShGEgSQL+L6S7gtwpYdg6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test data: Is it balance?\n",
    "counter = Counter(y_test)\n",
    "plt.bar(counter.keys(), counter.values())\n",
    "for k, v in counter.items():\n",
    "    dist = v/len(y_test) * 100\n",
    "    print(f\"Class={k}, n={v} ({dist}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fcb6bb",
   "metadata": {},
   "source": [
    "#### 3.6.2. GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e0f4f9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "852fccd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [119]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m xgb_estimator \u001b[38;5;241m=\u001b[39m XGBClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      9\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mxgb_estimator, \n\u001b[1;32m     10\u001b[0m                    param_grid\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m     11\u001b[0m                    scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     12\u001b[0m                    verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m grid_result \u001b[38;5;241m=\u001b[39m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_sc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_sc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest parameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, grid_result\u001b[38;5;241m.\u001b[39mbest_params_)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Accuracy: \u001b[39m\u001b[38;5;124m\"\u001b[39m, (grid_result\u001b[38;5;241m.\u001b[39mbest_score_))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_search.py:891\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    885\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    886\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    887\u001b[0m     )\n\u001b[1;32m    889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 891\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    894\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    895\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1392\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1391\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1392\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_search.py:838\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    831\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    832\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    833\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    834\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    835\u001b[0m         )\n\u001b[1;32m    836\u001b[0m     )\n\u001b[0;32m--> 838\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    857\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    859\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    860\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/joblib/parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1044\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1046\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1047\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1050\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1051\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1052\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/joblib/parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 861\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/joblib/parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    778\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 779\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:680\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    678\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 680\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    683\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    684\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/xgboost/core.py:575\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    574\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/xgboost/sklearn.py:1400\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1379\u001b[0m model, metric, params, early_stopping_rounds, callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_fit(\n\u001b[1;32m   1380\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1381\u001b[0m )\n\u001b[1;32m   1382\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1383\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[1;32m   1384\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1397\u001b[0m     enable_categorical\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menable_categorical,\n\u001b[1;32m   1398\u001b[0m )\n\u001b[0;32m-> 1400\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1401\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1402\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1403\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1404\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1405\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1406\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1408\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1409\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1410\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1411\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1412\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[1;32m   1415\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/xgboost/core.py:575\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    574\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/xgboost/training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/xgboost/core.py:1778\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_features(dtrain)\n\u001b[1;32m   1777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1778\u001b[0m     _check_call(\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1779\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1780\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1782\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'max_depth': [3,6,10], \n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'n_estimators': [100, 500, 1000],\n",
    "    'colsample_bytree': [0.3, 0.7],\n",
    "    'subsample':[0.5,1]}\n",
    "\n",
    "xgb_estimator = XGBClassifier(random_state=0)\n",
    "grid_search = GridSearchCV(estimator=xgb_estimator, \n",
    "                   param_grid=params,\n",
    "                   scoring='accuracy', \n",
    "                   verbose=1)\n",
    "\n",
    "grid_result = grid_search.fit(X_train_sc, y_train_sc)\n",
    "print(\"Best parameters:\", grid_result.best_params_)\n",
    "print(\"Best Accuracy: \", (grid_result.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfedbd3",
   "metadata": {},
   "source": [
    "PS: if time allows, it will be better if a grid search is performed to find the best combination of parameters to be used in the XGBClassifier. Currently it is stopped because it already took hours to compile (more than 6 hours)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6992db",
   "metadata": {},
   "source": [
    "## 4. Evaluation and Remodel\n",
    "Comparing each of the experimented model by its accuracy, precision, recall, False Positive Rates (FPR), AUC, and ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "8df75c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: xgb_1\n",
      "The accuracy of the xgb_1 model is 88.6%\n",
      "The precision of the xgb_1 model is 87.7%\n",
      "The recall score of the xgb_1 model is 39.1%\n",
      "The f1 score of the xgb_1 model is 54.1%\n",
      "==============================================================================\n",
      "Model: xgb_smote\n",
      "The accuracy of the xgb_smote model is 88.2%\n",
      "The precision of the xgb_smote model is 86.2%\n",
      "The recall score of the xgb_smote model is 37.3%\n",
      "The f1 score of the xgb_smote model is 52.1%\n",
      "==============================================================================\n",
      "Model: xgb_ada\n",
      "The accuracy of the xgb_ada model is 88.2%\n",
      "The precision of the xgb_ada model is 86.2%\n",
      "The recall score of the xgb_ada model is 37.3%\n",
      "The f1 score of the xgb_ada model is 52.1%\n",
      "==============================================================================\n",
      "Model: xgb_rus\n",
      "The accuracy of the xgb_rus model is 76.0%\n",
      "The precision of the xgb_rus model is 37.4%\n",
      "The recall score of the xgb_rus model is 59.4%\n",
      "The f1 score of the xgb_rus model is 45.9%\n",
      "==============================================================================\n",
      "Model: xgb_sc\n",
      "The accuracy of the xgb_sc model is 88.8%\n",
      "The precision of the xgb_sc model is 88.5%\n",
      "The recall score of the xgb_sc model is 39.800000000000004%\n",
      "The f1 score of the xgb_sc model is 54.900000000000006%\n",
      "==============================================================================\n",
      "Model: xgb_sc_tuned_1\n",
      "The accuracy of the xgb_sc_tuned_1 model is 88.6%\n",
      "The precision of the xgb_sc_tuned_1 model is 87.7%\n",
      "The recall score of the xgb_sc_tuned_1 model is 39.1%\n",
      "The f1 score of the xgb_sc_tuned_1 model is 54.1%\n",
      "==============================================================================\n",
      "Model: xgb_sc_tuned_2\n",
      "The accuracy of the xgb_sc_tuned_2 model is 88.8%\n",
      "The precision of the xgb_sc_tuned_2 model is 82.69999999999999%\n",
      "The recall score of the xgb_sc_tuned_2 model is 44.0%\n",
      "The f1 score of the xgb_sc_tuned_2 model is 57.4%\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    'xgb_1': y_pred_1,\n",
    "    'xgb_smote': y_pred_smote,\n",
    "    'xgb_ada': y_pred_ada,\n",
    "    'xgb_rus': y_pred_rus,\n",
    "    'xgb_sc': y_pred_sc,\n",
    "    'xgb_sc_tuned_1': y_pred_sc_tuned_1,\n",
    "    'xgb_sc_tuned_2': y_pred_sc_tuned_2\n",
    "}\n",
    "\n",
    "for key, val in models.items():\n",
    "    test = ''\n",
    "    # Selecting test set\n",
    "    if key == 'xgb_1':\n",
    "        test = y_test\n",
    "    elif key == 'xgb_sc' or key == 'xgb_sc_tuned_1' or key == 'xgb_sc_tuned_2':\n",
    "        test = y_test_sc\n",
    "    else:\n",
    "        test = y_test_nan_dropped\n",
    "        \n",
    "    \n",
    "    print(f\"Model: {key}\")\n",
    "    accuracy = accuracy_score(test,val)\n",
    "    print(f\"The accuracy of the {key} model is {round(accuracy,3)*100}%\")\n",
    "\n",
    "    precision = precision_score(test,val)\n",
    "    print(f\"The precision of the {key} model is {round(precision,3)*100}%\")\n",
    "\n",
    "    recall = recall_score(test,val)\n",
    "    print(f\"The recall score of the {key} model is {round(recall,3)*100}%\")\n",
    "\n",
    "    f1 = f1_score(test,val)\n",
    "    print(f\"The f1 score of the {key} model is {round(f1,3)*100}%\")\n",
    "    \n",
    "    print(\"==============================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb694800",
   "metadata": {},
   "source": [
    "### 4.1. Remodel and get the feature importance for the developed model\n",
    "From the evaluation above, it can be seen that xgb_sc model has the best f1 score of 54.9%, however, the training data was not resampled to make it balanced between each of the class (0 or 1). Therefore, in this section, an experiment to remodel with oversampled data train (i.e., using SMOTE) combined with dropping attributes with weak correlations to target variable y will be performed.\n",
    "\n",
    "note: xgb_smote (SMOTE oversampled) and xgb_sc (dropped attr. with weak correlations without oversampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "200b20dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversampled data with only strongly correlated attributes\n",
    "\n",
    "df_train_nan_dropped_sc = df_train_nan_dropped[:]\n",
    "\n",
    "X_train_nan_dropped_sc = df_train_nan_dropped_sc[sc_features].values\n",
    "y_train_nan_dropped_sc = df_train_nan_dropped_sc[target].values.flatten()\n",
    "\n",
    "X_train_smote_sc, y_train_smote_sc = smote.fit_resample(X_train_nan_dropped_sc, y_train_nan_dropped_sc)\n",
    "\n",
    "# Test data: use the NaN dropped: X_test_nan_dropped and y_test_nan_dropped with sc?????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "617ac117",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_nan_dropped_sc = df_test_nan_dropped[:]\n",
    "X_test_nan_dropped_sc = df_test_nan_dropped_sc[sc_features].values\n",
    "y_test_nan_dropped_sc = df_test_nan_dropped_sc[target].values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "f2f938c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class=0, n=70237 (50.0%)\n",
      "Class=1, n=70237 (50.0%)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "counter = Counter(y_train_smote_sc)\n",
    "plt.bar(counter.keys(), counter.values())\n",
    "for k, v in counter.items():\n",
    "    dist = v/len(y_train_smote_sc) * 100\n",
    "    print(f\"Class={k}, n={v} ({dist}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "03f8c30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model is 88.9%\n",
      "The precision of the model is 87.0%\n",
      "The recall of the model is 41.199999999999996%\n",
      "The f1 of the model is 55.900000000000006%\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "xgb_smote_sc = XGBClassifier(random_state=0)\n",
    "xgb_smote_sc.fit(X_train_smote_sc, y_train_smote_sc)\n",
    "\n",
    "# Prediction\n",
    "y_pred_smote_sc = xgb_smote_sc.predict(X_test_nan_dropped_sc)\n",
    "\n",
    "# Evaluation - accuracy\n",
    "accuracy_smote_sc = accuracy_score(y_test_nan_dropped_sc,y_pred_smote_sc)\n",
    "print(f\"The accuracy of the model is {round(accuracy_smote_sc,3)*100}%\")\n",
    "\n",
    "precision_smote_sc = precision_score(y_test_nan_dropped_sc,y_pred_smote_sc)\n",
    "print(f\"The precision of the model is {round(precision_smote_sc,3)*100}%\")\n",
    "\n",
    "recall_smote_sc = recall_score(y_test_nan_dropped_sc,y_pred_smote_sc)\n",
    "print(f\"The recall of the model is {round(recall_smote_sc,3)*100}%\")\n",
    "\n",
    "f1_smote_sc = f1_score(y_test_nan_dropped_sc,y_pred_smote_sc)\n",
    "print(f\"The f1 of the model is {round(f1_smote_sc,3)*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a217031e",
   "metadata": {},
   "source": [
    "The model performs better than previous ones. Now, its feature importance will be explored and by using attributes with feature importance >= 0.005, the model will be redeveloped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "ac3365b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x57',\n",
       " 'x41',\n",
       " 'x60',\n",
       " 'x44',\n",
       " 'x105',\n",
       " 'x67',\n",
       " 'x119',\n",
       " 'x61',\n",
       " 'x13',\n",
       " 'x62',\n",
       " 'x59',\n",
       " 'x72',\n",
       " 'x122',\n",
       " 'x107',\n",
       " 'x19',\n",
       " 'x82',\n",
       " 'x17',\n",
       " 'x106',\n",
       " 'x92',\n",
       " 'x91',\n",
       " 'x28',\n",
       " 'x46',\n",
       " 'x118',\n",
       " 'x96',\n",
       " 'x104',\n",
       " 'x117',\n",
       " 'x65',\n",
       " 'x75',\n",
       " 'x45',\n",
       " 'x35',\n",
       " 'x103',\n",
       " 'x39',\n",
       " 'x15',\n",
       " 'x50',\n",
       " 'x71',\n",
       " 'x31']"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature importance for model: xgb_smote_sc\n",
    "fi_xgb_smote_sc = xgb_smote_sc.feature_importances_\n",
    "relative_importance_fi_xgb_smote_sc = pd.DataFrame(index=sc_features, data=fi_xgb_smote_sc, columns=['importance'])\n",
    "fi_xgb_smote_sc_selected = relative_importance_fi_xgb_smote_sc.index[relative_importance_fi_xgb_smote_sc['importance'] >= 0.005].tolist()\n",
    "fi_xgb_smote_sc_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "a5fba241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redevelop the model with attributes that have feature importance of >= 0.005\n",
    "X_train_nan_dropped_sc_fi = df_train_nan_dropped_sc[fi_xgb_smote_sc_selected].values\n",
    "y_train_nan_dropped_sc_fi = df_train_nan_dropped_sc[target].values.flatten()\n",
    "\n",
    "X_train_smote_sc_fi, y_train_smote_sc_fi = smote.fit_resample(X_train_nan_dropped_sc_fi, y_train_nan_dropped_sc_fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "42e5ef28",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_nan_dropped_sc_fi = df_test_nan_dropped_sc[fi_xgb_smote_sc_selected].values\n",
    "y_test_nan_dropped_sc_fi = df_test_nan_dropped_sc[target].values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "f70d7b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model is 88.9%\n",
      "The precision of the model is 86.9%\n",
      "The recall of the model is 41.099999999999994%\n",
      "The f1 of the model is 55.800000000000004%\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "xgb_smote_sc_fi = XGBClassifier(random_state=0)\n",
    "xgb_smote_sc_fi.fit(X_train_smote_sc_fi, y_train_smote_sc_fi)\n",
    "\n",
    "# Prediction\n",
    "y_pred_smote_sc_fi = xgb_smote_sc_fi.predict(X_test_nan_dropped_sc_fi)\n",
    "\n",
    "# Evaluation - accuracy\n",
    "accuracy_smote_sc_fi = accuracy_score(y_test_nan_dropped_sc_fi,y_pred_smote_sc_fi)\n",
    "print(f\"The accuracy of the model is {round(accuracy_smote_sc_fi,3)*100}%\")\n",
    "\n",
    "precision_smote_sc_fi = precision_score(y_test_nan_dropped_sc_fi,y_pred_smote_sc_fi)\n",
    "print(f\"The precision of the model is {round(precision_smote_sc_fi,3)*100}%\")\n",
    "\n",
    "recall_smote_sc_fi = recall_score(y_test_nan_dropped_sc_fi,y_pred_smote_sc_fi)\n",
    "print(f\"The recall of the model is {round(recall_smote_sc_fi,3)*100}%\")\n",
    "\n",
    "f1_smote_sc_fi = f1_score(y_test_nan_dropped_sc_fi,y_pred_smote_sc_fi)\n",
    "print(f\"The f1 of the model is {round(f1_smote_sc_fi,3)*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343c00a2",
   "metadata": {},
   "source": [
    "The resulted model performs very slightly worse than the previos model xgb_smote_sc (without using only attributes with feature importance >= 0.005). Therefore, we will use the xgb_smote_sc model for the next experiment (i.e., perform hyperparameter tuning - intuitively).\n",
    "\n",
    "PS: Grid search for each combination of hyperparameter can be done to get the best combination for the model. However, it took too long to compile (as mentioned above, 6 hours are not enough). Therefore, in this case, hyperparameter tuning will be performed intuitively by using XGBoost's documentation as reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "3a795e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model is 88.9%\n",
      "The precision of the model is 87.0%\n",
      "The recall of the model is 41.199999999999996%\n",
      "The f1 of the model is 55.900000000000006%\n"
     ]
    }
   ],
   "source": [
    "# Model - Intuitive hyperparameter tuning\n",
    "xgb_smote_sc_tuned = XGBClassifier(random_state=0,max_depth=5,n_estimators=500,learning_rate=0.3,subsample=0.6,gamma=0.8,reg_lambda=1.2,alpha=0.2)\n",
    "xgb_smote_sc_tuned.fit(X_train_smote_sc, y_train_smote_sc)\n",
    "\n",
    "# Prediction\n",
    "y_pred_smote_sc_tuned = xgb_smote_sc_tuned.predict(X_test_nan_dropped_sc)\n",
    "\n",
    "# Evaluation - accuracy\n",
    "accuracy_smote_sc_tuned = accuracy_score(y_test_nan_dropped_sc,y_pred_smote_sc)\n",
    "print(f\"The accuracy of the model is {round(accuracy_smote_sc_tuned,3)*100}%\")\n",
    "\n",
    "precision_smote_sc_tuned = precision_score(y_test_nan_dropped_sc,y_pred_smote_sc)\n",
    "print(f\"The precision of the model is {round(precision_smote_sc_tuned,3)*100}%\")\n",
    "\n",
    "recall_smote_sc_tuned = recall_score(y_test_nan_dropped_sc,y_pred_smote_sc)\n",
    "print(f\"The recall of the model is {round(recall_smote_sc_tuned,3)*100}%\")\n",
    "\n",
    "f1_smote_sc_tuned = f1_score(y_test_nan_dropped_sc,y_pred_smote_sc)\n",
    "print(f\"The f1 of the model is {round(f1_smote_sc_tuned,3)*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593217cc",
   "metadata": {},
   "source": [
    "So the evaluation metrics for this tuned model is the same with xgb_smote_sc model. As mentioned, grid search is a good practice to be done to find the best combination of hyperparameters.\n",
    "\n",
    "Let's use this model as our final model to predict bank customer churn => model: <strong>xgb_smote_sc_tuned</strong>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b53be15",
   "metadata": {},
   "source": [
    "### 4.2. Prediction probabilities\n",
    "Prediction probabilities (predict_proba) accepts a single argument that corresponds to the data over which the probabilities will be computed and returns an array of lists containing the class probabilities for the input data points. This will be used to compute AUROC (Area Under the ROC curve) and ROC (Receiver Operating Characteristics) curve values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "254e6d8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9494996 , 0.05050038],\n",
       "       [0.7606261 , 0.23937394],\n",
       "       [0.92256457, 0.07743543],\n",
       "       ...,\n",
       "       [0.03680599, 0.963194  ],\n",
       "       [0.84717435, 0.15282567],\n",
       "       [0.953823  , 0.04617703]], dtype=float32)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_smote_sc_tuned_probs = xgb_smote_sc_tuned.predict_proba(X_test_nan_dropped_sc)\n",
    "xgb_smote_sc_tuned_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b742ccf0",
   "metadata": {},
   "source": [
    "Probabilities for the positive outcome is kept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "b7ea25d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05050038, 0.23937394, 0.07743543, ..., 0.963194  , 0.15282567,\n",
       "       0.04617703], dtype=float32)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_smote_sc_tuned_probs = xgb_smote_sc_tuned_probs[:, 1]\n",
    "xgb_smote_sc_tuned_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf655103",
   "metadata": {},
   "source": [
    "### 4.3. Computing AUROC and ROC curve values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "181e9cdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7501569826173384"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate AUROC\n",
    "xgb_smote_sc_tuned_auc = roc_auc_score(y_test_nan_dropped_sc,xgb_smote_sc_tuned_probs)\n",
    "xgb_smote_sc_tuned_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "6fd98688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False Positive Rate: [0.         0.         0.         ... 0.99965628 0.99965628 1.        ]\n",
      "True Positive Rate: [0.00000000e+00 2.77469478e-04 1.10987791e-03 ... 9.99722531e-01\n",
      " 1.00000000e+00 1.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "# Calculate ROC Curve\n",
    "xgb_smote_sc_tuned_fpr, xgb_smote_sc_tuned_tpr, _ = roc_curve(y_test_nan_dropped_sc, xgb_smote_sc_tuned_probs)\n",
    "fpr = xgb_smote_sc_tuned_fpr\n",
    "tpr = xgb_smote_sc_tuned_tpr\n",
    "print(f\"False Positive Rate: {fpr}\")\n",
    "print(f\"True Positive Rate: {tpr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "4395f959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the ROC curve\n",
    "\n",
    "# random prediction as baseline in the ROC plot\n",
    "r_probs = [0 for _ in range(len(y_test_nan_dropped_sc))]\n",
    "r_auc = roc_auc_score(y_test_nan_dropped_sc, r_probs)\n",
    "r_fpr,r_tpr,_= roc_curve(y_test_nan_dropped_sc, r_probs)\n",
    "\n",
    "plt.plot(r_fpr, r_tpr, linestyle='--', label='Random prediction (AUROC = %0.3f)' % r_auc)\n",
    "plt.plot(xgb_smote_sc_tuned_fpr, xgb_smote_sc_tuned_tpr, marker='.', label='XGB SMOTE oversampled with dropping features with weak correlations (AUROC = %0.3f)'%xgb_smote_sc_tuned_auc)\n",
    "\n",
    "# Title\n",
    "plt.title('ROC Plot')\n",
    "# Axis label\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "# Show legend\n",
    "plt.legend()\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "e8ae6f73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bank_cust_churn_pred.joblib']"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using joblib (as a file)\n",
    "from joblib import dump, load\n",
    "dump(xgb_smote_sc_tuned, 'bank_cust_churn_pred.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "6bd5d20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predicted values as a csv file\n",
    "pred_df = pd.DataFrame(y_pred_smote_sc_tuned,columns=['Prediction'])\n",
    "pred_df.to_csv(f\"Bank_Churn_Predicted_Output.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
